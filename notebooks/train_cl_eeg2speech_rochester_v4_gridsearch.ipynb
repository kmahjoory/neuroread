{"cells":[{"cell_type":"markdown","metadata":{"id":"VhCK252zNjUG"},"source":["## COLAB TOOLS"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23820,"status":"ok","timestamp":1677786092316,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"v-pxnK4OaI-b","outputId":"baef4e61-35e4-4c38-b606-26983f75da97"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554,"referenced_widgets":["b0bb2a650ba0447d832f6a1bf47dd4b4","736632aa328443f7a1e9a85d67da40da"]},"executionInfo":{"elapsed":9612,"status":"ok","timestamp":1677770794960,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"ZEopbadxbJH0","outputId":"61d52ff8-8996-4d44-8a4d-acf612b32e54"},"outputs":[{"name":"stdout","output_type":"stream","text":["['.git', '.DS_Store', '.gitignore', 'EEG', 'LICENSE', 'train_cl_eeg2speech_rochester_v1.ipynb', 'train_cl_eeg2speech_rochester_v2.ipynb', '.ipynb_checkpoints', 'train_cl_eeg2speech_rochester_v3_test_old.ipynb', 'runs', 'train_cl_eeg2speech_rochester_v3_test.ipynb', 'train_cl_eeg2speech_rochester_v4_gridseaerch.ipynb', 'train_cl_eeg2speech_2.ipynb', 'train_cl_eeg2speech_rochester_subj_2.ipynb', 'README.md', 'train_eeg2speech_rochester.ipynb', 'train_cl_eeg2speech_rochester_v3.ipynb', 'train_cl_eeg2speech_rochester_v3_test_gridsearch.ipynb']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n","Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n","To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","</pre>\n"],"text/plain":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Collecting mne\n","</pre>\n"],"text/plain":["Collecting mne\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n","</pre>\n"],"text/plain":["  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0bb2a650ba0447d832f6a1bf47dd4b4","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","</pre>\n"],"text/plain":["\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mne) (23.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mne) (23.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: scipy&gt;=1.1.0 in /usr/local/lib/python3.8/dist-packages (from mne) (1.7.3)\n","</pre>\n"],"text/plain":["Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from mne) (1.7.3)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from mne) (4.4.2)\n","</pre>\n"],"text/plain":["Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from mne) (4.4.2)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mne) (3.5.3)\n","</pre>\n"],"text/plain":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mne) (3.5.3)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from mne) (4.64.1)\n","</pre>\n"],"text/plain":["Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from mne) (4.64.1)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pooch&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from mne) (1.6.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.8/dist-packages (from mne) (1.6.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: numpy&gt;=1.15.4 in /usr/local/lib/python3.8/dist-packages (from mne) (1.22.4)\n","</pre>\n"],"text/plain":["Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.8/dist-packages (from mne) (1.22.4)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from mne) (3.1.2)\n","</pre>\n"],"text/plain":["Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from mne) (3.1.2)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: appdirs&gt;=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch&gt;=1.5-&gt;mne) (1.4.4)\n","</pre>\n"],"text/plain":["Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.5->mne) (1.4.4)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: requests&gt;=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch&gt;=1.5-&gt;mne) (2.25.1)\n","</pre>\n"],"text/plain":["Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.5->mne) (2.25.1)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2-&gt;mne) (2.1.2)\n","</pre>\n"],"text/plain":["Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->mne) (2.1.2)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (1.4.4)\n","</pre>\n"],"text/plain":["Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (1.4.4)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (2.8.2)\n","</pre>\n"],"text/plain":["Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (2.8.2)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (0.11.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (0.11.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pyparsing&gt;=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (3.0.9)\n","</pre>\n"],"text/plain":["Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (3.0.9)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (4.38.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (4.38.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (8.4.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (8.4.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;mne) (1.15.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->mne) (1.15.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (2.10)\n","</pre>\n"],"text/plain":["Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (2022.12.7)\n","</pre>\n"],"text/plain":["Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.12.7)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (4.0.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (4.0.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (1.26.14)\n","</pre>\n"],"text/plain":["Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.14)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Installing collected packages: mne\n","</pre>\n"],"text/plain":["Installing collected packages: mne\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully installed mne-1.3.1\n","</pre>\n"],"text/plain":["Successfully installed mne-1.3.1\n"]},"metadata":{},"output_type":"display_data"}],"source":["\n","import os\n","import sys\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"Colab Notebooks/prj_neuroread_analysis/neuroread/\"\n","GOOGLE_DRIVE_PATH = os.path.join(\"/content\", \"drive\", \"MyDrive\", GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n","# Add to sys so we can import .py files.\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","os.chdir(GOOGLE_DRIVE_PATH)\n","\n","# Install unavailable packages\n","import pip\n","def import_or_install(package):\n","    try:\n","        __import__(package)\n","    except ImportError:\n","        pip.main(['install', package])\n","\n","import_or_install(\"mne\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1677770794961,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"M0LuZowEbY29"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1677770794961,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"HTqIrJcOaQLu","outputId":"e68bf150-1e5d-4dc9-bfd9-584df1883136"},"outputs":[{"name":"stdout","output_type":"stream","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","Thu Mar  2 15:26:33 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n"," print('Not connected to a GPU')\n","else:\n"," print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"aXEXbz7ENjUM"},"source":["## Main code"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677770794962,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"EOmC9QbE-kZz"},"outputs":[],"source":["#%reset"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5065,"status":"ok","timestamp":1677770800021,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"gGggzCoKZQeu","outputId":"520b7a55-a9ff-4ea6-9339-951589cd19bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["import os, sys, glob\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","\n","import mne\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import time\n","\n","from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1677770800021,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"GYgZe_3OQniG"},"outputs":[],"source":["def eval_model_cl(dl, model, device=torch.device('cpu'), verbose=True):\n","    \"\"\" \n","    This function calculates the loss on data, setting backward gradients and batchnorm\n","    off. This function is written for contrasting learning where the model takes in two\n","    inputs.\n","\n","    Args:\n","\n","    Returns:\n","      loss_test: Mean loss of all test samples (scalar)\n","\n","    \"\"\"\n","    losses, losses_X1, losses_X2 = [], [], []\n","    model.to(device)  # inplace for model\n","    # Set the model in evaluation mode\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for idx_batch, (X1b, X2b) in enumerate(dl):\n","\n","            X1b = X1b.to(device)\n","            X2b = X2b.to(device)\n","\n","            X1b_features, X2b_features, logit_sc = model(X1b, X2b)\n","\n","            # Normalize features\n","            X1b_f_n = X1b_features / X1b_features.norm(dim=1, keepdim=True)\n","            X2b_f_n = X2b_features / X2b_features.norm(dim=1, keepdim=True)\n","\n","            logits_per_X1 = logit_sc * X1b_f_n @ X2b_f_n.t()\n","            logits_per_X2 = logits_per_X1.t()\n","\n","            # Number of labels equals to the 1st dimension of X1b\n","            labels = torch.arange(X1b.shape[0], device=device)\n","\n","            # Batch Loss \n","            loss_X1 = F.cross_entropy(logits_per_X1, labels)\n","            loss_X2 = F.cross_entropy(logits_per_X2, labels)\n","            loss_batch   = (loss_X1 + loss_X2) / 2\n","            losses.append(loss_batch.item())\n","            losses_X1.append(loss_X1.item())\n","            losses_X2.append(loss_X2.item())\n","\n","        # Epoch loss (mean of batch losses)\n","        loss  = sum(losses) / len(losses)\n","        loss_X1 = sum(losses_X1) / len(losses_X1)\n","        loss_X2 = sum(losses_X2) / len(losses_X2)\n","\n","        if verbose:\n","          print(f\"====> Validation loss: {loss:.4f},  X1 loss: {loss_X1:.4f}   X2 loss: {loss_X2:.4f}\")\n","\n","        return loss, loss_X1, loss_X2\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1677770800022,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"EaAsZ-SLZQey"},"outputs":[],"source":["def unfold_raw(raw, window_size=None, stride=None):\n","    \"\"\"\n","    This function unfolds raw MNE object into a list of raw objects\n","    Args:\n","        raw: a raw MNE object cropped by rejecting bad segments.\n","    Returns:\n","        raw_unfolded: a raw MNE object unfolded by applying a sliding window.\n","    \"\"\"\n","    if window_size is None:\n","        window_size = int(5 * raw.info['sfreq'])\n","    if stride is None:\n","        stride = window_size\n","    nchans = len(raw.ch_names)\n","    sig = torch.tensor(raw.get_data(), dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n","    sig_unf = F.unfold(sig, (nchans, window_size), stride=stride , padding=0)\n","    sig_unf = sig_unf.permute(0, 2, 1).reshape(-1, sig_unf.shape[-1], nchans, window_size)\n","    return sig_unf"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1677770800022,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"1cf9EoF3ZQey"},"outputs":[],"source":["def rm_repeated_annotations(raw):\n","    \"\"\"This functions taskes in raw MNE obejct and removes repeated annotations\"\"\"\n","    annots = raw.annotations.copy()\n","    annots_drop = []\n","    for k in annots:\n","        annots_drop.extend([k for kk in annots if (k['onset'] > kk['onset']) and (k['onset']+k['duration'] < kk['onset']+kk['duration']) ])\n","\n","    annots_updated = [i for i in annots if i not in annots_drop]\n","    onsets = [i['onset'] for i in annots_updated]\n","    durations = [i['duration'] for i in annots_updated]\n","    descriptions = [i['description'] for i in annots_updated]\n","    print('Initial num of annots: %d  Num of removed annots: %d  Num of retained annots:  %d' % (len(annots), len(annots_drop), len(annots_updated)))\n","    print(f' New annots: {annots_updated}')\n","    raw.set_annotations(mne.Annotations(onsets, durations, descriptions) ) \n","    return raw"]},{"cell_type":"markdown","metadata":{"id":"q4sGJAdFZQez"},"source":["## Read Data"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1677770800022,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"KdQFfHcJZQe0","outputId":"277bf1f6-a0d2-4ab0-d473-164315b2b943"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------------\n","window_size: 640  stride_size_test: 640\n","data_path: ../outputs/rochester_data/natural_speech\n"]}],"source":["subj_ids = list(range(1, 20))\n","fs = 128\n","window_size = int(5 * fs)\n","stride_size_train, stride_size_val, stride_size_test = int(2.5 * fs), int(5 * fs), int(5 * fs)\n","n_channs = 129 # 128 for eeg, 1 for env\n","batch_size = int(32)\n","print('-------------------------------------')\n","print(f'window_size: {window_size}  stride_size_test: {stride_size_test}')\n","\n","dataset_name = ['rochester_data', 'natural_speech']\n","outputs_path = f'../outputs/'\n","data_path = os.path.join(outputs_path, dataset_name[0], dataset_name[1])\n","after_ica_path = os.path.join(data_path, 'after_ica_raw')\n","print(f'data_path: {data_path}')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278442,"status":"ok","timestamp":1677771078457,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"fIhJi5IxZQe1","outputId":"8000353a-a618-4919-f1de-ec3947e126f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_1_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 48  Num of removed annots: 19  Num of retained annots:  29\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.559097), ('duration', 2.240447998046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.084473), ('duration', 2.24041748046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.212158), ('duration', 2.0118408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.890503), ('duration', 2.67486572265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 899.02771), ('duration', 2.05755615234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 983.746643), ('duration', 6.58416748046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1051.039551), ('duration', 1.8746337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1100.719482), ('duration', 6.4012451171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1265.987061), ('duration', 3.269287109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.989502), ('duration', 2.080322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1611.904297), ('duration', 11.796630859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.480591), ('duration', 3.81787109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1977.884644), ('duration', 8.5731201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2058.135986), ('duration', 5.052490234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2161.450928), ('duration', 3.2236328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.70874), ('duration', 1.8291015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.632324), ('duration', 5.578369140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2656.933838), ('duration', 3.246337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2699.549561), ('duration', 15.7060546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2892.681641), ('duration', 3.497802734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2977.071045), ('duration', 1.64599609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3079.503906), ('duration', 8.321533203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3220.774658), ('duration', 3.017822265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3257.32251), ('duration', 10.927978515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3327.002441), ('duration', 6.584228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3438.776123), ('duration', 5.806884765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3480.157471), ('duration', 12.139404296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3607.381592), ('duration', 10.49365234375), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 26  N val: 1  N test: 1\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_2_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 65  Num of removed annots: 19  Num of retained annots:  46\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 177.009033), ('duration', 4.4808807373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 233.547455), ('duration', 3.1549072265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 256.64325), ('duration', 4.549468994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.877777), ('duration', 1.554595947265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 419.798157), ('duration', 4.18365478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 521.238403), ('duration', 3.72650146484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 536.986145), ('duration', 8.36737060546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 591.58136), ('duration', 12.36810302734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 684.541626), ('duration', 37.07598876953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 731.651611), ('duration', 0.9830322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 760.453308), ('duration', 5.80682373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 895.355164), ('duration', 14.21990966796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 955.299988), ('duration', 3.9779052734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1010.325623), ('duration', 5.5782470703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1047.856567), ('duration', 3.0177001953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.390625), ('duration', 4.892333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.681152), ('duration', 8.984619140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1304.783569), ('duration', 3.2464599609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1385.044556), ('duration', 3.749267578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.464355), ('duration', 2.171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.947266), ('duration', 13.3740234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1636.351562), ('duration', 1.600341796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1650.508545), ('duration', 8.5731201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1683.526245), ('duration', 6.5384521484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1726.90979), ('duration', 6.2640380859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.079224), ('duration', 13.076904296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.602295), ('duration', 1.348876953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1991.061035), ('duration', 2.126220703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2049.411133), ('duration', 4.503662109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2136.050537), ('duration', 4.732421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.68042), ('duration', 11.659423828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2234.577881), ('duration', 7.315673828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.926758), ('duration', 14.63134765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.343262), ('duration', 9.076171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2546.635498), ('duration', 3.177734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.869873), ('duration', 15.68310546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.512939), ('duration', 8.481689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3081.322021), ('duration', 2.468994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3087.928955), ('duration', 6.835693359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3116.119141), ('duration', 3.886474609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3257.709961), ('duration', 6.652587890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3280.65918), ('duration', 5.71533203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3440.005615), ('duration', 0.914306640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3452.968018), ('duration', 7.29296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3604.318115), ('duration', 3.817138671875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 68  N val: 2  N test: 2\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_3_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 47  Num of removed annots: 19  Num of retained annots:  28\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 43.135948), ('duration', 4.115089416503906), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 121.796593), ('duration', 5.6010894775390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.748077), ('duration', 1.760345458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 275.317291), ('duration', 2.994842529296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.205322), ('duration', 2.126129150390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.65863), ('duration', 1.89752197265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.599854), ('duration', 2.12615966796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.988525), ('duration', 1.6231689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1033.410278), ('duration', 0.9830322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.293579), ('duration', 1.7603759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.313721), ('duration', 3.56640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1307.502563), ('duration', 0.86865234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.074097), ('duration', 2.4461669921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1583.876953), ('duration', 0.3658447265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.867554), ('duration', 1.9432373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.839478), ('duration', 1.9661865234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.358643), ('duration', 2.1947021484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.061523), ('duration', 2.14892578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.888916), ('duration', 0.8916015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.831299), ('duration', 2.92626953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.159668), ('duration', 2.01171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2790.049561), ('duration', 9.510498046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.086426), ('duration', 2.400390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3081.215576), ('duration', 1.874755859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.645996), ('duration', 2.14892578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.272217), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3525.888916), ('duration', 1.87451171875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 93  N val: 3  N test: 3\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_4_after_ica_raw.fif...\n","    Range : 0 ... 464394 =      0.000 ...  3628.078 secs\n","Ready.\n","Reading 0 ... 464394  =      0.000 ...  3628.078 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.316391), ('duration', 2.4461822509765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.619507), ('duration', 1.074493408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.230835), ('duration', 1.851806640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.968323), ('duration', 4.89239501953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.236755), ('duration', 2.56048583984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1100.372314), ('duration', 2.5833740234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1265.114136), ('duration', 4.6181640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.281372), ('duration', 1.874755859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.327759), ('duration', 1.783203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.417358), ('duration', 1.2344970703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1981.789795), ('duration', 2.720458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2161.278076), ('duration', 4.8466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2344.500732), ('duration', 1.80615234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.130127), ('duration', 2.194580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.033447), ('duration', 2.743408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2876.088623), ('duration', 1.6689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2892.718506), ('duration', 0.822998046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3079.622803), ('duration', 2.217529296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.026855), ('duration', 6.172607421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3438.603516), ('duration', 0.822998046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3535.585693), ('duration', 2.720458984375), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 112  N val: 4  N test: 4\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_5_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 177.408173), ('duration', 0.270477294921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 358.121857), ('duration', 0.270477294921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.280273), ('duration', 1.9835205078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.369812), ('duration', 2.3441162109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 899.271362), ('duration', 1.3974609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.870972), ('duration', 0.4508056640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.272949), ('duration', 1.4425048828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.279663), ('duration', 1.126953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.049805), ('duration', 1.8707275390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1701.652954), ('duration', 0.96923828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.822144), ('duration', 2.434326171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.066284), ('duration', 2.186279296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2161.976074), ('duration', 1.983642578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.484619), ('duration', 1.870849609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2524.411133), ('duration', 0.541015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.077393), ('duration', 2.569580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.742432), ('duration', 0.8564453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3081.496094), ('duration', 0.653564453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3229.895752), ('duration', 1.84814453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.698975), ('duration', 2.727294921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.993408), ('duration', 0.901611328125), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 131  N val: 5  N test: 5\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_6_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 58  Num of removed annots: 19  Num of retained annots:  39\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.775345), ('duration', 1.6688995361328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 282.102112), ('duration', 2.56048583984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.346893), ('duration', 2.263275146484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 523.917664), ('duration', 2.1260986328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 536.834473), ('duration', 2.56048583984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.924316), ('duration', 5.0753173828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 757.242065), ('duration', 2.65191650390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 837.127747), ('duration', 3.177734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 879.596802), ('duration', 2.5147705078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 897.584961), ('duration', 4.526611328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.219971), ('duration', 2.0574951171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1218.668945), ('duration', 2.4461669921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.177368), ('duration', 1.7603759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1405.632324), ('duration', 2.3089599609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.297607), ('duration', 1.8746337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1469.58728), ('duration', 2.03466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1497.78125), ('duration', 2.4461669921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1554.397705), ('duration', 10.470703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1608.48999), ('duration', 8.39013671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1634.155762), ('duration', 2.468994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1747.676392), ('duration', 4.3209228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.026855), ('duration', 1.6002197265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.125), ('duration', 2.7890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2036.889648), ('duration', 4.7322998046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2122.203125), ('duration', 2.03466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.363037), ('duration', 1.623291015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2253.597656), ('duration', 2.491943359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.462646), ('duration', 2.034912109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2487.927979), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2524.04541), ('duration', 1.92041015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2603.16333), ('duration', 1.8974609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.935303), ('duration', 2.743408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.359375), ('duration', 2.0576171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.958984), ('duration', 1.783203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3111.987793), ('duration', 0.64013671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.530518), ('duration', 2.8349609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3403.469971), ('duration', 1.1201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.724609), ('duration', 1.028564453125), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 167  N val: 6  N test: 6\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_7_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 74  Num of removed annots: 18  Num of retained annots:  56\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.368912), ('duration', 2.6062164306640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 202.71106), ('duration', 3.5206756591796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 315.806854), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 356.574677), ('duration', 2.903411865234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 534.393311), ('duration', 6.35552978515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.769409), ('duration', 1.44024658203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 899.308594), ('duration', 2.5147705078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 981.924255), ('duration', 1.8289794921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 995.180115), ('duration', 2.53765869140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1054.425659), ('duration', 13.945556640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1091.636597), ('duration', 3.54345703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1100.598267), ('duration', 3.2235107421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1187.123291), ('duration', 1.851806640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.292847), ('duration', 1.2574462890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1323.053955), ('duration', 1.5089111328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.083496), ('duration', 1.8289794921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1504.320801), ('duration', 2.354736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1536.858521), ('duration', 5.1666259765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.278198), ('duration', 1.9432373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1668.210327), ('duration', 2.766357421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1713.217041), ('duration', 1.80615234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1729.60498), ('duration', 3.1319580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1784.040039), ('duration', 8.756103515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1805.663208), ('duration', 3.7950439453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.498901), ('duration', 2.0574951171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2096.175781), ('duration', 2.37744140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2157.560791), ('duration', 10.72216796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2288.804688), ('duration', 3.955078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2330.930908), ('duration', 2.468994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.640381), ('duration', 1.600341796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2363.354248), ('duration', 2.080322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2398.324707), ('duration', 2.354736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.527588), ('duration', 2.53759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2550.565186), ('duration', 6.149658203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.920654), ('duration', 2.857666015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.047607), ('duration', 2.26318359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2912.270264), ('duration', 3.2919921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2929.330566), ('duration', 3.08642578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2943.047607), ('duration', 4.09228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2969.869873), ('duration', 3.497802734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2992.805664), ('duration', 3.246337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3006.655762), ('duration', 2.743408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.669922), ('duration', 3.04052734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3104.24585), ('duration', 2.171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3139.366943), ('duration', 1.463134765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3160.199219), ('duration', 6.67578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3224.72583), ('duration', 9.05322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.845459), ('duration', 2.6748046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3312.975098), ('duration', 3.132080078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3358.553223), ('duration', 2.8349609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3393.308594), ('duration', 2.080322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3432.110352), ('duration', 2.583251953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3440.40625), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3503.788574), ('duration', 3.360595703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3555.731934), ('duration', 7.33837890625), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 220  N val: 7  N test: 7\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_8_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 42  Num of removed annots: 19  Num of retained annots:  23\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.14798), ('duration', 2.926300048828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.06424), ('duration', 2.2633056640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 371.421326), ('duration', 5.235321044921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 536.955017), ('duration', 4.4808349609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.692444), ('duration', 2.37762451171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.715332), ('duration', 2.65191650390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.184326), ('duration', 2.19482421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.598633), ('duration', 2.743408203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.696045), ('duration', 5.6468505859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.613281), ('duration', 11.3165283203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.690186), ('duration', 2.53759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.835938), ('duration', 1.348876953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.807617), ('duration', 0.8916015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2344.188721), ('duration', 3.269287109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2377.503662), ('duration', 2.92626953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.80957), ('duration', 1.874755859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.339844), ('duration', 1.87451171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2716.461426), ('duration', 2.240478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2888.094238), ('duration', 7.0185546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.641357), ('duration', 2.2861328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.550049), ('duration', 2.652099609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.231689), ('duration', 2.19482421875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 240  N val: 8  N test: 8\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_9_after_ica_raw.fif...\n","    Range : 0 ... 464396 =      0.000 ...  3628.094 secs\n","Ready.\n","Reading 0 ... 464396  =      0.000 ...  3628.094 secs...\n","Initial num of annots: 50  Num of removed annots: 19  Num of retained annots:  31\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 130.882126), ('duration', 1.5317230224609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 175.55928), ('duration', 3.543548583984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 264.037018), ('duration', 2.994873046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 356.953827), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.136719), ('duration', 2.60626220703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.279785), ('duration', 2.19476318359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 805.422119), ('duration', 2.03466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 863.707458), ('duration', 1.5089111328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.531311), ('duration', 2.1947021484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 942.221497), ('duration', 1.16595458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1100.621216), ('duration', 2.103271484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.725952), ('duration', 1.2344970703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1361.294312), ('duration', 1.851806640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1436.863159), ('duration', 3.3377685546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1612.4375), ('duration', 5.2352294921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1627.293579), ('duration', 2.6519775390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1664.12915), ('duration', 145.87548828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.199341), ('duration', 14.970458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2160.909668), ('duration', 2.720458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2343.753906), ('duration', 3.955078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2376.438232), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2522.852783), ('duration', 2.08056640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2621.444824), ('duration', 2.2861328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2704.782715), ('duration', 5.006591796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2779.488281), ('duration', 3.4521484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2890.36084), ('duration', 4.572509765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3018.792969), ('duration', 2.2861328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3073.694824), ('duration', 8.207275390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3260.755127), ('duration', 1.966064453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3437.777588), ('duration', 2.468994140625), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 268  N val: 9  N test: 9\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_10_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 69  Num of removed annots: 18  Num of retained annots:  51\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 149.729568), ('duration', 2.286163330078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.793808), ('duration', 1.5088653564453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 211.101257), ('duration', 1.3259735107421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 304.370483), ('duration', 2.6748046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.593964), ('duration', 3.429229736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 423.59317), ('duration', 4.526611328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 492.564392), ('duration', 6.309814453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.557739), ('duration', 1.6231689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 572.701599), ('duration', 2.994873046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 612.724426), ('duration', 2.5833740234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 719.066589), ('duration', 4.8466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 811.009827), ('duration', 2.1260986328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 880.173401), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 887.100464), ('duration', 2.21759033203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 900.03125), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1025.614502), ('duration', 2.81201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.146973), ('duration', 3.8636474609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1150.301147), ('duration', 2.14892578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1233.59314), ('duration', 1.7603759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.456787), ('duration', 3.0406494140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1362.038574), ('duration', 3.6578369140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.113892), ('duration', 3.4520263671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1486.748047), ('duration', 2.3319091796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1505.262085), ('duration', 3.4063720703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.439087), ('duration', 1.0516357421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1756.245117), ('duration', 4.2523193359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.182495), ('duration', 1.828857421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1922.290039), ('duration', 2.1490478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.267212), ('duration', 5.3724365234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2112.381592), ('duration', 7.91015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.427246), ('duration', 3.93212890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2216.300293), ('duration', 7.27001953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2331.169922), ('duration', 2.560546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2344.951416), ('duration', 2.69775390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2499.67041), ('duration', 1.486083984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.835205), ('duration', 3.2919921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2550.506836), ('duration', 3.54345703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2649.912354), ('duration', 2.994873046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.953857), ('duration', 4.09228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.044434), ('duration', 3.0634765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2913.181641), ('duration', 3.360595703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2961.087891), ('duration', 3.223388671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2998.279785), ('duration', 3.360595703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.013428), ('duration', 6.88134765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3253.579834), ('duration', 17.740478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3347.544434), ('duration', 2.62890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3420.438232), ('duration', 2.53759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3438.906494), ('duration', 3.109130859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3501.901367), ('duration', 2.03466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3572.518799), ('duration', 1.828857421875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 315  N val: 10  N test: 10\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_11_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 78  Num of removed annots: 19  Num of retained annots:  59\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 177.039948), ('duration', 4.3952178955078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.18277), ('duration', 2.32159423828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 435.710114), ('duration', 1.48760986328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.806274), ('duration', 5.29681396484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 671.660583), ('duration', 1.893310546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.955811), ('duration', 1.44256591796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 899.639587), ('duration', 0.833984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.750732), ('duration', 1.7130126953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1206.979858), ('duration', 2.006103515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.227905), ('duration', 3.876708984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1295.597412), ('duration', 7.190185546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.611084), ('duration', 2.5694580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1481.968506), ('duration', 2.9075927734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1580.556152), ('duration', 4.5303955078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.591431), ('duration', 6.2659912109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1637.656128), ('duration', 5.3643798828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1651.32251), ('duration', 1.5777587890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1775.785278), ('duration', 4.0797119140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1791.269775), ('duration', 18.189453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1932.201538), ('duration', 3.1329345703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.449463), ('duration', 2.38916015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2151.615479), ('duration', 2.006103515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.539551), ('duration', 1.53271484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2233.644043), ('duration', 2.34423828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2278.166992), ('duration', 9.42138671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2315.965576), ('duration', 1.6455078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2343.441162), ('duration', 7.55078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2426.551758), ('duration', 2.25390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2470.736328), ('duration', 1.623046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.974609), ('duration', 10.030029296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2551.818359), ('duration', 2.299072265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2593.869385), ('duration', 2.862548828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2637.603516), ('duration', 2.636962890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2668.505127), ('duration', 2.772216796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2705.033936), ('duration', 14.5830078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2730.661133), ('duration', 3.6064453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2771.908447), ('duration', 4.84619140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2806.206055), ('duration', 8.00146484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2829.624512), ('duration', 14.8310546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2880.150391), ('duration', 2.2314453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.381104), ('duration', 3.49365234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2907.363037), ('duration', 3.268310546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2940.218018), ('duration', 2.456787109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2961.750732), ('duration', 1.600341796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3074.462891), ('duration', 13.208251953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3097.363037), ('duration', 2.592041015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3190.803955), ('duration', 3.49365234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3207.333008), ('duration', 1.9384765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3230.285645), ('duration', 6.6943359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3262.396729), ('duration', 8.452392578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3306.897217), ('duration', 16.431396484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3346.10083), ('duration', 1.1044921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3388.452393), ('duration', 3.854248046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3416.048096), ('duration', 1.825927734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3431.630371), ('duration', 11.144287109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3490.585938), ('duration', 32.209228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3547.460693), ('duration', 14.222412109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3602.553955), ('duration', 2.163330078125), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 371  N val: 11  N test: 11\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_12_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 51  Num of removed annots: 19  Num of retained annots:  32\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.551804), ('duration', 2.30902099609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.795807), ('duration', 1.3717041015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.433899), ('duration', 1.73748779296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.997986), ('duration', 1.92041015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.792236), ('duration', 2.78912353515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.352783), ('duration', 2.354736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1182.130005), ('duration', 4.275146484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.908081), ('duration', 2.2633056640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.174927), ('duration', 1.6231689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.036987), ('duration', 1.9432373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1682.048096), ('duration', 5.5782470703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.885254), ('duration', 2.7662353515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1960.644043), ('duration', 3.132080078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.518677), ('duration', 2.81201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2073.501709), ('duration', 2.0576171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2093.70752), ('duration', 2.2861328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2150.264893), ('duration', 14.699951171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2344.736328), ('duration', 3.612060546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2396.222168), ('duration', 3.657958984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2471.718506), ('duration', 2.629150390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2516.94043), ('duration', 9.78466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.397705), ('duration', 3.246337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.067383), ('duration', 3.772216796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3015.650635), ('duration', 2.263427734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3050.07251), ('duration', 2.65185546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3061.819336), ('duration', 1.96630859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.908936), ('duration', 1.828857421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.169922), ('duration', 3.840576171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3377.466309), ('duration', 3.81787109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3403.113037), ('duration', 2.8349609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.432373), ('duration', 2.217529296875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 400  N val: 12  N test: 12\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_13_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.160904), ('duration', 3.20062255859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 356.484039), ('duration', 3.921905517578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 536.904724), ('duration', 2.592041015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.437378), ('duration', 3.9444580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.459961), ('duration', 3.718994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1100.759033), ('duration', 3.290771484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1194.230103), ('duration', 4.6431884765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.822144), ('duration', 2.6822509765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1280.82666), ('duration', 6.4913330078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.520874), ('duration', 2.862548828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.734253), ('duration', 3.155517578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.175903), ('duration', 2.7799072265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1981.855835), ('duration', 3.1104736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2161.750732), ('duration', 5.251708984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.169189), ('duration', 3.1103515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.666504), ('duration', 2.299072265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.213623), ('duration', 6.58154296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2892.855225), ('duration', 2.907470703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.285645), ('duration', 3.8994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.300049), ('duration', 3.51611328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3438.414795), ('duration', 4.7109375), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 419  N val: 13  N test: 13\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_14_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 39  Num of removed annots: 19  Num of retained annots:  20\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.866791), ('duration', 1.280242919921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.495789), ('duration', 1.806060791015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.569763), ('duration', 1.53173828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.69519), ('duration', 2.5516357421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.344482), ('duration', 18.97515869140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.503296), ('duration', 1.577392578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.323975), ('duration', 1.80615234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1437.978271), ('duration', 2.171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.346436), ('duration', 1.25732421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.185791), ('duration', 1.14306640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.707642), ('duration', 1.7374267578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.391357), ('duration', 1.80615234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.696777), ('duration', 1.6689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.895752), ('duration', 1.943115234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.303711), ('duration', 1.966064453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.481445), ('duration', 2.01171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.663818), ('duration', 2.514892578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.868164), ('duration', 2.240478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.161133), ('duration', 2.606201171875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 436  N val: 14  N test: 14\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_15_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 58  Num of removed annots: 17  Num of retained annots:  41\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 76.757561), ('duration', 2.5147705078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.666107), ('duration', 3.2234954833984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 233.021637), ('duration', 2.286163330078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 358.273438), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 467.283386), ('duration', 2.88055419921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.214783), ('duration', 4.64093017578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 559.249451), ('duration', 2.6748046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 588.357849), ('duration', 2.9034423828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.988525), ('duration', 3.177734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.755981), ('duration', 18.609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1029.203735), ('duration', 2.606201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.430786), ('duration', 3.5892333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1129.967651), ('duration', 4.7552490234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1145.463867), ('duration', 18.5865478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.972778), ('duration', 16.871826171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1380.918335), ('duration', 1.6917724609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.449341), ('duration', 5.976318359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1594.484741), ('duration', 2.4691162109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.213989), ('duration', 6.5384521484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1729.902954), ('duration', 5.692626953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1782.38147), ('duration', 2.30908203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.250977), ('duration', 2.2862548828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1934.608521), ('duration', 0.983154296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1944.027588), ('duration', 2.6748046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1983.453125), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2058.1521), ('duration', 8.595947265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.345215), ('duration', 3.97802734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.797363), ('duration', 1.325927734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2524.51709), ('duration', 1.486083984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2597.877686), ('duration', 2.011962890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2615.614502), ('duration', 0.6171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.567139), ('duration', 18.35791015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2867.613037), ('duration', 6.3095703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.899902), ('duration', 4.34375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3068.35791), ('duration', 14.677001953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3092.162354), ('duration', 9.0302734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3239.912354), ('duration', 2.171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3260.712646), ('duration', 5.578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.967773), ('duration', 9.62451171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3518.847412), ('duration', 38.1884765625), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 474  N val: 15  N test: 15\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_16_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 67  Num of removed annots: 19  Num of retained annots:  48\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 51.486004), ('duration', 1.2116661071777344), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 68.906548), ('duration', 3.703582763671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 174.80484), ('duration', 4.09222412109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 216.666107), ('duration', 1.6688995361328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 269.821014), ('duration', 7.841522216796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.73114), ('duration', 1.440277099609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 506.163147), ('duration', 3.086334228515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 538.014954), ('duration', 1.211669921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 546.894714), ('duration', 3.10919189453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 557.639709), ('duration', 3.8406982421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 705.72876), ('duration', 3.9322509765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.325562), ('duration', 2.468994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 782.871094), ('duration', 0.68585205078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 788.677917), ('duration', 1.5089111328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 816.908142), ('duration', 2.97198486328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 860.735474), ('duration', 1.89752197265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.517883), ('duration', 2.30902099609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 954.174194), ('duration', 0.960205078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 985.568726), ('duration', 11.86517333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1029.683838), ('duration', 7.531005859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.59082), ('duration', 1.348876953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1110.950684), ('duration', 3.6807861328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.420532), ('duration', 1.1202392578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.586426), ('duration', 2.6063232421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1523.753174), ('duration', 8.6875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1546.702393), ('duration', 2.971923828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.540039), ('duration', 1.8746337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.388184), ('duration', 2.103271484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.770142), ('duration', 6.1041259765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2052.038574), ('duration', 3.2919921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2085.271484), ('duration', 1.2802734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2156.757568), ('duration', 9.464599609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.705811), ('duration', 1.8291015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2524.58374), ('duration', 1.5546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.580566), ('duration', 9.213134765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2727.809082), ('duration', 3.040771484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2829.523926), ('duration', 2.857666015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2875.467773), ('duration', 2.0576171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.730469), ('duration', 2.37744140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2919.843994), ('duration', 1.98876953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3013.854248), ('duration', 1.805908203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.826904), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3227.740723), ('duration', 5.646728515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3262.439697), ('duration', 1.76025390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3343.341797), ('duration', 1.98876953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3391.878662), ('duration', 3.1318359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3440.14624), ('duration', 1.463134765625), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 519  N val: 16  N test: 16\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_17_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 41  Num of removed annots: 19  Num of retained annots:  22\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.793808), ('duration', 2.0803985595703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.681488), ('duration', 1.53173828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.955811), ('duration', 8.481689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 719.217163), ('duration', 1.66888427734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 899.511047), ('duration', 2.12615966796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.398438), ('duration', 2.2861328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.037598), ('duration', 3.406494140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.683716), ('duration', 4.4580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.033325), ('duration', 2.217529296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.266235), ('duration', 1.4403076171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.798828), ('duration', 5.143798828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.341553), ('duration', 2.354736328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.542236), ('duration', 2.65185546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.233154), ('duration', 3.337890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2596.991943), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2706.753906), ('duration', 2.857666015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.46167), ('duration', 2.0576171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2925.00293), ('duration', 5.0068359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3081.097656), ('duration', 2.49169921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3262.227295), ('duration', 3.26904296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.470459), ('duration', 2.126220703125), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 538  N val: 17  N test: 17\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_18_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 73  Num of removed annots: 19  Num of retained annots:  54\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 170.203079), ('duration', 8.913589477539062), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 206.867218), ('duration', 4.327606201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 349.474213), ('duration', 12.171417236328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 454.838654), ('duration', 6.62664794921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.76123), ('duration', 20.360595703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 626.025635), ('duration', 1.82574462890625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 675.191711), ('duration', 5.27423095703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 719.297607), ('duration', 1.44256591796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 772.945312), ('duration', 3.9444580078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 802.10376), ('duration', 5.657470703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 824.2901), ('duration', 1.7806396484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 837.332947), ('duration', 2.38922119140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 890.841553), ('duration', 10.25555419921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 935.830383), ('duration', 2.43426513671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 958.84314), ('duration', 4.14727783203125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1002.697388), ('duration', 4.84600830078125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1058.535156), ('duration', 19.9774169921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.577759), ('duration', 28.0167236328125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1156.56665), ('duration', 1.82568359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1191.840942), ('duration', 2.9976806640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1209.782227), ('duration', 19.1361083984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1258.505005), ('duration', 11.6634521484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1350.398315), ('duration', 3.3133544921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1415.762817), ('duration', 2.09619140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.537842), ('duration', 1.4200439453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1496.351562), ('duration', 3.4710693359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1541.347778), ('duration', 4.2374267578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.345581), ('duration', 1.82568359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1649.371826), ('duration', 2.434326171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1716.148682), ('duration', 2.7723388671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.343262), ('duration', 2.1412353515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1855.74292), ('duration', 2.727294921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1883.331299), ('duration', 3.313232421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.85791), ('duration', 2.0511474609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2071.535645), ('duration', 3.831787109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.144287), ('duration', 3.26806640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2346.058594), ('duration', 1.487548828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2524.31543), ('duration', 2.163818359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2541.107422), ('duration', 2.794921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2605.92334), ('duration', 2.749755859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.290527), ('duration', 1.375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2721.107422), ('duration', 3.538818359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2825.547607), ('duration', 1.9384765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.744629), ('duration', 2.343994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3080.904541), ('duration', 1.9833984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3250.205811), ('duration', 1.55517578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3262.828125), ('duration', 1.87060546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3310.010498), ('duration', 2.07373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3390.28833), ('duration', 18.30224609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3426.757324), ('duration', 3.899169921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.574707), ('duration', 2.411865234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3513.023193), ('duration', 2.36669921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3537.395996), ('duration', 2.36669921875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 589  N val: 18  N test: 18\n","Opening raw data file ../outputs/rochester_data/natural_speech/after_ica_raw/subj_19_after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 63  Num of removed annots: 19  Num of retained annots:  44\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 25.705925), ('duration', 2.3318824768066406), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.51947), ('duration', 2.491912841796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 264.471405), ('duration', 1.851776123046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 293.684631), ('duration', 0.93731689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.260529), ('duration', 3.81787109375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.717773), ('duration', 5.029541015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 557.94635), ('duration', 4.8466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 614.324768), ('duration', 2.65191650390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 629.569519), ('duration', 3.49786376953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 670.323975), ('duration', 2.606201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 719.279297), ('duration', 3.772216796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 847.809204), ('duration', 2.56048583984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 899.4552), ('duration', 4.16082763671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 956.300354), ('duration', 0.5029296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.741333), ('duration', 0.8916015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1119.478149), ('duration', 2.468994140625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1245.363037), ('duration', 1.440185546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1267.452881), ('duration', 2.103271484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1290.196289), ('duration', 1.966064453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.517944), ('duration', 1.3487548828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1528.586426), ('duration', 5.6468505859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1614.252319), ('duration', 1.6688232421875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1623.694092), ('duration', 2.171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1673.012207), ('duration', 2.65185546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1728.668457), ('duration', 1.64599609375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1774.621948), ('duration', 1.4403076171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1807.27002), ('duration', 1.5545654296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1980.470581), ('duration', 6.368896484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2084.347656), ('duration', 2.606201171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.541504), ('duration', 1.600341796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2240.104736), ('duration', 2.240478515625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.751709), ('duration', 3.360595703125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2462.884521), ('duration', 1.989013671875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2515.372559), ('duration', 11.210693359375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2540.735596), ('duration', 6.05810546875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.283447), ('duration', 6.904052734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2726.803223), ('duration', 0.868896484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.876953), ('duration', 3.909423828125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3081.398438), ('duration', 3.155029296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3207.433838), ('duration', 2.2177734375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3262.26709), ('duration', 7.27001953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.821045), ('duration', 2.03466796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3557.260498), ('duration', 2.629150390625), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 630  N val: 19  N test: 19\n","Shape Trian: torch.Size([21765, 1, 129, 640])  Shape Val: torch.Size([714, 1, 129, 640])  Shape Test: torch.Size([685, 1, 129, 640])\n","-------------------------------------\n","Shape EEG Train: torch.Size([21765, 1, 128, 640])  Val: torch.Size([714, 1, 128, 640])  Test: torch.Size([685, 1, 128, 640])\n","Mean: 6.165832427962314e-11  Std: 5.718287411582423e-06\n","Shape Env Train: torch.Size([21765, 1, 1, 640])  Val: torch.Size([714, 1, 1, 640])  Test: torch.Size([685, 1, 1, 640])\n","Mean Env: 2.3698980808258057  Std Env: 2.5990054607391357\n"]}],"source":["raws_train_windowed, raws_val_windowed, raws_test_windowed = [], [], []\n","\n","for subj_id in subj_ids:\n","    \n","\n","    # load subject raw MNE object\n","    raw = mne.io.read_raw(os.path.join(after_ica_path, f'subj_{subj_id}_after_ica_raw.fif'), preload=True)\n","    # drop M1 and M2 channels\n","    raw.drop_channels(['M1', 'M2'])\n","    assert raw.info['nchan'] == n_channs\n","\n","    raw = rm_repeated_annotations(raw)\n","    annots = raw.annotations.copy()\n","    raw_split = [raw.copy().crop(t1, t2) for t1, t2 in zip(annots.onset[:-1]+annots.duration[:-1], annots.onset[1:])]\n","\n","    # Pick the split with the longest duration for validation, supposedly less noisy\n","    ix_val = np.argmax([i.get_data().shape[1] for i in raw_split])\n","    raw_val = [raw_split.pop(ix_val)] # create a list to make it iterable. later may be used for multiple splits\n","\n","    # Pick the next split with the longest duration for testing, supposedly less noisy\n","    ix_test = np.argmax([i.get_data().shape[1] for i in raw_split])\n","    raw_test = [raw_split.pop(ix_test)]\n","    \n","    # creat list of unfolded tensor raw objects\n","    fs = raw.info['sfreq']\n","    raws_train_windowed.extend([unfold_raw(i, window_size=window_size, stride=stride_size_train) for i in raw_split if i.get_data().shape[1] > window_size])\n","    raws_val_windowed.extend([unfold_raw(i, window_size=window_size, stride=stride_size_val) for i in raw_val if i.get_data().shape[1] > window_size])\n","    raws_test_windowed.extend([unfold_raw(i, window_size=window_size, stride=stride_size_test) for i in raw_test if i.get_data().shape[1] > window_size])\n","    print(\"-------------------------------------\")\n","    print('N train: %d  N val: %d  N test: %d' % (len(raws_train_windowed), len(raws_val_windowed), len(raws_test_windowed)))\n","\n","# concatenate all in second dimension\n","sigs_train = torch.cat(raws_train_windowed, dim=1).permute(1, 0, 2, 3)\n","sigs_val = torch.cat(raws_val_windowed, dim=1).permute(1, 0, 2, 3)\n","sigs_test = torch.cat(raws_test_windowed, dim=1).permute(1, 0, 2, 3)\n","print(f\"Shape Trian: {sigs_train.shape}  Shape Val: {sigs_val.shape}  Shape Test: {sigs_test.shape}\")\n","\n","eegs_train = sigs_train[:, :, :-1, :]\n","eegs_val = sigs_val[:, :, :-1, :]\n","eegs_test = sigs_test[:, :, :-1, :]\n","print(\"-------------------------------------\")\n","print(f\"Shape EEG Train: {eegs_train.shape}  Val: {eegs_val.shape}  Test: {eegs_test.shape}\")\n","\n","# To avoid information leakage, we estimate the mean and std from the training set only.\n","mean_eeg_train =  eegs_train.mean()\n","std_eeg_train = eegs_train.std()\n","print(f\"Mean: {mean_eeg_train}  Std: {std_eeg_train}\")\n","\n","envs_train = sigs_train[:, :, [-1], :]\n","envs_val = sigs_val[:, :, [-1], :]\n","envs_test = sigs_test[:, :, [-1], :]\n","print(f\"Shape Env Train: {envs_train.shape}  Val: {envs_val.shape}  Test: {envs_test.shape}\")\n","\n","# Estimate mean and std of the Envelope data set\n","mean_env_train =  envs_train.mean()\n","std_env_train = envs_train.std()\n","print(f\"Mean Env: {mean_env_train}  Std Env: {std_env_train}\")\n","\n","# Normalize the data\n","eegs_train = (eegs_train - mean_eeg_train) / std_eeg_train\n","eegs_val = (eegs_val - mean_eeg_train) / std_eeg_train\n","eegs_test = (eegs_test - mean_eeg_train) / std_eeg_train\n","\n","envs_train = (envs_train - mean_env_train) / std_env_train\n","envs_val = (envs_val - mean_env_train) / std_env_train\n","envs_test = (envs_test - mean_env_train) / std_env_train\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tesRTfOdZQe2"},"source":["### Pytorch dataloader"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1677771078458,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"HviGOmH1ZQe2"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, eeg, env):\n","        self.eeg = eeg\n","        self.env = env\n","    \n","    def __getitem__(self, index):\n","        return self.eeg[index], self.env[index]\n","    \n","    def __len__(self):\n","        return len(self.eeg)\n","    \n","dataset_train = MyDataset(eegs_train, envs_train)\n","dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","dl_val = DataLoader(MyDataset(eegs_val, envs_val), batch_size=batch_size, shuffle=True, drop_last=True)"]},{"cell_type":"markdown","metadata":{"id":"XMjI2NeFZQe3"},"source":["## Model"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1677771078458,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"57o2oV6VZQe3"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1677771078458,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"IffWKmD6ZQe3"},"outputs":[],"source":["# My implementation of the shallow convnet\n","\n","fs = 64 # sampling rate\n","T = 5 * fs # number of time points in each trial\n","C = 64 # number of EEG channels\n","F1 = 8 # number of channels (depth) in the first conv layer\n","D = 2 # number of spatial filters in the second conv layer\n","F2 = D * F1 # number of channels (depth) in the pont-wise conv layer\n","num_classes = 4 # number of classes\n","\n","shallow_covnet = Sequential([\n","    Conv2d(1, 40, (1, int(fs//2)), padding='same', bias=True),\n","    Conv2d(40, 40, (C, 1), padding=(0, 0), bias=False), nn.BatchNorm2d(40, affine=True), \n","    nn.AvgPool2d((1, 75), (1, 15)), nn.Dropout(0.5),\n","    Conv2d(40, 4, kernel_size=(1, 30), padding='same', stride=(1, 1), bias=True),\n","    nn.Flatten(1, -1), # Flatten start_dim=1, end_dim=-1\n","    Linear(62*4, 4, bias=True),\n","])\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1677771078459,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"bT-TwE-oTAHE","outputId":"6f4820bb-8f64-451b-9d7e-49ef1e901b65"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 32])\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]}],"source":["## EEG Encoder with LINEAR\n","\n","class EEGEncoderWithLinear(nn.Module):\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            C = 128, # number of EEG channels\n","            F1 = 8, # 8 or 4 number of channels (depth) in the first conv layer\n","            D = 2, # number of spatial filters in the second conv layer\n","            F2 = None # number of channels (depth) in the pont-wise conv layer\n","            linear = False\n","        ):\n","        super(EEGEncoderWithLinear, self).__init__()\n","\n","        if F2 is None:\n","            F2 = D * F1\n","\n","        self.eeg_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs/2)), padding='same', bias=True, groups=1),\n","            nn.BatchNorm2d(F1, affine=True),\n","            Conv2d(F1, out_channels=D*F1, kernel_size=(C, 1), padding=(0, 0), bias=False, groups=F1),\n","            nn.BatchNorm2d(D*F1, affine=True), ELU(), nn.AvgPool2d(1, 4), nn.Dropout(0.25),\n","                    \n","            Conv2d(F2, F2, (1, int(fs/(2*4))), padding='same', bias=False, groups=D*F1),\n","            Conv2d(D*F1, F2, kernel_size=(1, 1), padding=(0, 0), groups=1, bias=False),\n","            nn.BatchNorm2d(F2, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.25),\n","\n","            nn.Flatten()\n","        )\n","        self.linear = nn.Sequential(\n","            nn.Linear(F2*int((T*fs)//(8*4)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.eeg_encoder(x)\n","        return x\n","\n","\n","def normalize_weights_eegnet(eeg_encoder):\n","\n","    for ix, (name, param) in enumerate(eeg_encoder.named_parameters()):\n","        if  name == 'weight' and param.ndim==4 and ix==1: # normalize conv weights to max norm 1\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=1)\n","        elif name == 'weight' and param.ndim==2: # normalize fc weights to max norm 0.25\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=0.25)\n","\n","\n","eeg_encoder_with_linear = EEGEncoderWithLinear()\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(eeg_encoder_with_linear(eegs_train[:32, :, :, :]).shape)\n","\n","#summary(eeg_encoder_with_linear, (1, 128, 640))"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1677771078459,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"sQjEWHA4ZQe4","outputId":"68198b94-04c4-4120-8d81-5fcb82e51804"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 320])\n"]}],"source":["## EEG Encoder NO LINEAR\n","\n","class EEGEncoderNoLinear(nn.Module):\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            C = 128, # number of EEG channels\n","            F1 = 8, # 8 or 4 number of channels (depth) in the first conv layer\n","            D = 2, # number of spatial filters in the second conv layer\n","            F2 = None # number of channels (depth) in the pont-wise conv layer\n","        ):\n","        super(EEGEncoderNoLinear, self).__init__()\n","\n","        if F2 is None:\n","            F2 = D * F1\n","\n","        self.eeg_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs/2)), padding='same', bias=True, groups=1),\n","            nn.BatchNorm2d(F1, affine=True),\n","            Conv2d(F1, out_channels=D*F1, kernel_size=(C, 1), padding=(0, 0), bias=False, groups=F1),\n","            nn.BatchNorm2d(D*F1, affine=True), ELU(), nn.AvgPool2d(1, 4), nn.Dropout(0.25),\n","                    \n","            Conv2d(F2, F2, (1, int(fs/(2*4))), padding='same', bias=False, groups=D*F1),\n","            Conv2d(D*F1, F2, kernel_size=(1, 1), padding=(0, 0), groups=1, bias=False),\n","            nn.BatchNorm2d(F2, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.25),\n","\n","            nn.Flatten(),\n","            #nn.Linear(F2*int((T*fs)//(8*4)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.eeg_encoder(x)\n","        return x\n","\n","\n","def normalize_weights_eegnet(eeg_encoder):\n","\n","    for ix, (name, param) in enumerate(eeg_encoder.named_parameters()):\n","        if  name == 'weight' and param.ndim==4 and ix==1: # normalize conv weights to max norm 1\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=1)\n","        elif name == 'weight' and param.ndim==2: # normalize fc weights to max norm 0.25\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=0.25)\n","\n","\n","eeg_encoder_no_linear = EEGEncoderNoLinear()\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(eeg_encoder_no_linear(eegs_train[:32, :, :, :]).shape)\n","\n","#summary(eeg_encoder_no_linear, (1, 128, 640))"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1677771078459,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"SfO-UwlzZQe4","outputId":"c93bcce5-f2c7-4361-db84-974f9856594e"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 320])\n"]}],"source":["class EnvEncoder3ConvNoLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder3ConvNoLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//8)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            #nn.Linear(F1*int((T*fs)//(2*8)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder3conv_no_linear = EnvEncoder3ConvNoLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder3conv_no_linear(envs_train[:32, :, :, :]).shape)\n","#summary(env_encoder3conv_no_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1677771078460,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"EHbSd3XITAHF","outputId":"7f777437-64bf-45f3-9b84-206e7fc4adb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 320])\n"]}],"source":["class EnvEncoder2ConvNoLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder2ConvNoLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 16), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            #nn.Linear(F1*int((T*fs)//(2*8)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder2conv_no_linear = EnvEncoder2ConvNoLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder2conv_no_linear(envs_train[:32, :, :, :]).shape)\n","#summary(env_encoder2conv_no_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1677771078460,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"2914ppmhTAHG","outputId":"96a53d4e-15eb-4a96-efd3-22504a3570b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 32])\n"]}],"source":["class EnvEncoder2ConvWithLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder2ConvWithLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 16), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            nn.Linear(F1*4*int((T*fs)//(8*4)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder2conv_with_linear = EnvEncoder2ConvWithLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder2conv_with_linear(envs_train[:32, :, :, :]).shape)\n","#summary(env_encoder2conv_with_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1677771078461,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"ojZIx-6eTAHG","outputId":"f240735c-27cd-432a-8784-c20c38ac2470"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 32])\n"]}],"source":["class EnvEncoder3ConvWithLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder3ConvWithLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//8)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            nn.Linear(F1*4*int((T*fs)//(4*8)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder3conv_with_linear = EnvEncoder3ConvWithLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder3conv_with_linear(envs_train[:32, :, :, :]).shape)\n","#summary(env_encoder3conv_with_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4836,"status":"ok","timestamp":1677771083288,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"Bp8HVS-aZQe4","outputId":"bfc6ed4c-597d-4eca-fd42-7b8252567639"},"outputs":[{"data":{"text/plain":["CES()"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["class CES(nn.Module):\n","    def __init__(self, \n","                 eeg_encoder= None,\n","                 env_encoder = None): \n","        super().__init__()\n","\n","        self.eeg_encoder = eeg_encoder\n","        self.env_encoder = env_encoder\n","        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n","\n","    def encode_eeg(self, x):\n","        return self.eeg_encoder(x)\n","    \n","    def encode_env(self, x):\n","        return self.env_encoder(x)\n","    \n","    def forward(self, eeg, env):\n","        eeg_features = self.encode_eeg(eeg)\n","        env_features = self.encode_env(env)\n","        return eeg_features, env_features, self.logit_scale.exp()\n","  \n","\n","model = CES();\n","model.to(device)\n","#for n,p in model.named_parameters():\n","    #print(n, p.shape)\n"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1677771083288,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"kRK-Pq1VTAHG","outputId":"c44a9c51-f6a3-4c6b-adb8-fc7d59b52358"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Models with no Linear Layers\n"," Models with Linear Layers\n"]}],"source":["print(\" Models with no Linear Layers\")\n","eeg_encoder_no_linear = EEGEncoderNoLinear()\n","env_encoder3conv_no_linear = EnvEncoder2ConvNoLinear()\n","ces_eeg_0lin_env_3conv_0lin = CES(eeg_encoder=eeg_encoder_no_linear.eeg_encoder, env_encoder=env_encoder2conv_no_linear.env_encoder)\n","#summary(ces_eeg_0lin_env_3conv_0lin, [(1, 128, 640), (1, 1, 640)])\n","\n","eeg_encoder_no_linear = EEGEncoderNoLinear()\n","env_encoder2conv_no_linear = EnvEncoder2ConvNoLinear()\n","ces_eeg_0lin_env_2conv_0lin = CES(eeg_encoder=eeg_encoder_no_linear.eeg_encoder, env_encoder=env_encoder2conv_no_linear.env_encoder)\n","#summary(ces_eeg_0lin_env_2conv_0lin, [(1, 128, 640), (1, 1, 640)])\n","\n","\n","print(\" Models with Linear Layers\")\n","eeg_encoder_with_linear = EEGEncoderWithLinear()\n","env_encoder3conv_with_linear = EnvEncoder2ConvWithLinear()\n","ces_eeg_1lin_env_3conv_1lin = CES(eeg_encoder=eeg_encoder_with_linear.eeg_encoder, env_encoder=env_encoder3conv_with_linear.env_encoder)\n","#summary(ces_eeg_1lin_env_3conv_1lin, [(1, 128, 640), (1, 1, 640)])\n","\n","eeg_encoder_with_linear = EEGEncoderWithLinear()\n","env_encoder2conv_with_linear = EnvEncoder2ConvWithLinear()\n","ces_eeg_1lin_env_2conv_1lin = CES(eeg_encoder=eeg_encoder_with_linear.eeg_encoder, env_encoder=env_encoder2conv_with_linear.env_encoder)\n","#summary(ces_eeg_1lin_env_2conv_1lin, [(1, 128, 640), (1, 1, 640)])\n","\n","models_name = [\"eeg0lin_env3conv0lin\", \"eeg0lin_env2conv0lin\"]#, \"eeg1lin_env3conv1lin\", \"eeg1lin_env2conv1lin\"]\n","models_dict = {\"eeg0lin_env3conv0lin\": ces_eeg_0lin_env_3conv_0lin, \"eeg0lin_env2conv0lin\": ces_eeg_0lin_env_2conv_0lin} #, \n","              # \"eeg1lin_env3conv1lin\": ces_eeg_1lin_env_3conv_1lin, \"eeg1lin_env2conv1lin\": ces_eeg_1lin_env_2conv_1lin}\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":8511458,"status":"ok","timestamp":1677781695965,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"d4iJiosNZQe7","outputId":"7cee43df-ead8-41a4-e403-46d0eee82c01"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------New model: eeg0lin_env3conv0lin----------------------+\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","</pre>\n"],"text/plain":["Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">NumExpr defaulting to 8 threads.\n","</pre>\n"],"text/plain":["NumExpr defaulting to 8 threads.\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["====== Epoch: 1\n","====> Validation loss: 3.1942,  X1 loss: 3.1826   X2 loss: 3.2059\n","====== Epoch: 2\n","====> Validation loss: 3.0680,  X1 loss: 3.0598   X2 loss: 3.0763\n","====== Epoch: 3\n","====> Validation loss: 3.0121,  X1 loss: 3.0091   X2 loss: 3.0150\n","====== Epoch: 4\n","====> Validation loss: 2.9504,  X1 loss: 2.9454   X2 loss: 2.9554\n","====== Epoch: 5\n","====> Validation loss: 2.9691,  X1 loss: 2.9659   X2 loss: 2.9724\n","====== Epoch: 6\n","====> Validation loss: 2.9167,  X1 loss: 2.9102   X2 loss: 2.9231\n","====== Epoch: 7\n","====> Validation loss: 2.8942,  X1 loss: 2.8834   X2 loss: 2.9050\n","====== Epoch: 8\n","====> Validation loss: 2.8731,  X1 loss: 2.8664   X2 loss: 2.8798\n","====== Epoch: 9\n","====> Validation loss: 2.8699,  X1 loss: 2.8635   X2 loss: 2.8764\n","====== Epoch: 10\n","====> Validation loss: 2.8772,  X1 loss: 2.8566   X2 loss: 2.8978\n","====== Epoch: 11\n","====> Validation loss: 2.8760,  X1 loss: 2.8696   X2 loss: 2.8824\n","====== Epoch: 12\n","====> Validation loss: 2.8725,  X1 loss: 2.8632   X2 loss: 2.8818\n","====== Epoch: 13\n","====> Validation loss: 2.8541,  X1 loss: 2.8403   X2 loss: 2.8678\n","====== Epoch: 14\n","====> Validation loss: 2.8175,  X1 loss: 2.8064   X2 loss: 2.8286\n","====== Epoch: 15\n","====> Validation loss: 2.8222,  X1 loss: 2.8063   X2 loss: 2.8381\n","====== Epoch: 16\n","====> Validation loss: 2.8414,  X1 loss: 2.8302   X2 loss: 2.8527\n","====== Epoch: 17\n","====> Validation loss: 2.8375,  X1 loss: 2.8222   X2 loss: 2.8529\n","====== Epoch: 18\n","====> Validation loss: 2.8499,  X1 loss: 2.8400   X2 loss: 2.8599\n","====== Epoch: 19\n","====> Validation loss: 2.7932,  X1 loss: 2.7775   X2 loss: 2.8089\n","====== Epoch: 20\n","====> Validation loss: 2.8056,  X1 loss: 2.7945   X2 loss: 2.8167\n","====== Epoch: 21\n","====> Validation loss: 2.8361,  X1 loss: 2.8277   X2 loss: 2.8445\n","====== Epoch: 22\n","====> Validation loss: 2.8597,  X1 loss: 2.8517   X2 loss: 2.8677\n","====== Epoch: 23\n","====> Validation loss: 2.8039,  X1 loss: 2.7923   X2 loss: 2.8155\n","====== Epoch: 24\n","====> Validation loss: 2.7868,  X1 loss: 2.7744   X2 loss: 2.7992\n","====== Epoch: 25\n","====> Validation loss: 2.7916,  X1 loss: 2.7789   X2 loss: 2.8043\n","====== Epoch: 26\n","====> Validation loss: 2.7951,  X1 loss: 2.7807   X2 loss: 2.8095\n","====== Epoch: 27\n","====> Validation loss: 2.7778,  X1 loss: 2.7669   X2 loss: 2.7887\n","====== Epoch: 28\n","====> Validation loss: 2.7785,  X1 loss: 2.7749   X2 loss: 2.7822\n","====== Epoch: 29\n","====> Validation loss: 2.7665,  X1 loss: 2.7612   X2 loss: 2.7718\n","====== Epoch: 30\n","====> Validation loss: 2.8273,  X1 loss: 2.8227   X2 loss: 2.8318\n","====== Epoch: 31\n","====> Validation loss: 2.8142,  X1 loss: 2.8052   X2 loss: 2.8231\n","====== Epoch: 32\n","====> Validation loss: 2.7758,  X1 loss: 2.7632   X2 loss: 2.7884\n","====== Epoch: 33\n","====> Validation loss: 2.7405,  X1 loss: 2.7284   X2 loss: 2.7526\n","====== Epoch: 34\n","====> Validation loss: 2.7812,  X1 loss: 2.7635   X2 loss: 2.7988\n","====== Epoch: 35\n","====> Validation loss: 2.7884,  X1 loss: 2.7743   X2 loss: 2.8025\n","====== Epoch: 36\n","====> Validation loss: 2.7419,  X1 loss: 2.7333   X2 loss: 2.7505\n","====== Epoch: 37\n","====> Validation loss: 2.7054,  X1 loss: 2.6913   X2 loss: 2.7195\n","====== Epoch: 38\n","====> Validation loss: 2.7530,  X1 loss: 2.7374   X2 loss: 2.7687\n","====== Epoch: 39\n","====> Validation loss: 2.7454,  X1 loss: 2.7309   X2 loss: 2.7600\n","====== Epoch: 40\n","====> Validation loss: 2.7717,  X1 loss: 2.7576   X2 loss: 2.7858\n","====== Epoch: 41\n","====> Validation loss: 2.7801,  X1 loss: 2.7720   X2 loss: 2.7882\n","====== Epoch: 42\n","====> Validation loss: 2.7548,  X1 loss: 2.7456   X2 loss: 2.7641\n","====== Epoch: 43\n","====> Validation loss: 2.7329,  X1 loss: 2.7228   X2 loss: 2.7430\n","====== Epoch: 44\n","====> Validation loss: 2.7292,  X1 loss: 2.7218   X2 loss: 2.7366\n","====== Epoch: 45\n","====> Validation loss: 2.7244,  X1 loss: 2.7144   X2 loss: 2.7343\n","====== Epoch: 46\n","====> Validation loss: 2.7316,  X1 loss: 2.7181   X2 loss: 2.7451\n","====== Epoch: 47\n","====> Validation loss: 2.7617,  X1 loss: 2.7416   X2 loss: 2.7817\n","====== Epoch: 48\n","====> Validation loss: 2.6926,  X1 loss: 2.6865   X2 loss: 2.6987\n","====== Epoch: 49\n","====> Validation loss: 2.7767,  X1 loss: 2.7607   X2 loss: 2.7927\n","====== Epoch: 50\n","====> Validation loss: 2.7316,  X1 loss: 2.7168   X2 loss: 2.7464\n","====== Epoch: 51\n","====> Validation loss: 2.7195,  X1 loss: 2.7110   X2 loss: 2.7280\n","====== Epoch: 52\n","====> Validation loss: 2.7213,  X1 loss: 2.7042   X2 loss: 2.7385\n","====== Epoch: 53\n","====> Validation loss: 2.7252,  X1 loss: 2.7066   X2 loss: 2.7437\n","====== Epoch: 54\n","====> Validation loss: 2.6997,  X1 loss: 2.6861   X2 loss: 2.7134\n","====== Epoch: 55\n","====> Validation loss: 2.6838,  X1 loss: 2.6743   X2 loss: 2.6933\n","====== Epoch: 56\n","====> Validation loss: 2.7140,  X1 loss: 2.7013   X2 loss: 2.7267\n","====== Epoch: 57\n","====> Validation loss: 2.7026,  X1 loss: 2.6956   X2 loss: 2.7096\n","====== Epoch: 58\n","====> Validation loss: 2.7154,  X1 loss: 2.7067   X2 loss: 2.7242\n","====== Epoch: 59\n","====> Validation loss: 2.6993,  X1 loss: 2.6895   X2 loss: 2.7092\n","====== Epoch: 60\n","====> Validation loss: 2.7071,  X1 loss: 2.6969   X2 loss: 2.7174\n","====== Epoch: 61\n","====> Validation loss: 2.7147,  X1 loss: 2.7032   X2 loss: 2.7262\n","====== Epoch: 62\n","====> Validation loss: 2.6949,  X1 loss: 2.6853   X2 loss: 2.7045\n","====== Epoch: 63\n","====> Validation loss: 2.6719,  X1 loss: 2.6520   X2 loss: 2.6918\n","====== Epoch: 64\n","====> Validation loss: 2.6808,  X1 loss: 2.6680   X2 loss: 2.6936\n","====== Epoch: 65\n","====> Validation loss: 2.6750,  X1 loss: 2.6517   X2 loss: 2.6983\n","====== Epoch: 66\n","====> Validation loss: 2.6624,  X1 loss: 2.6480   X2 loss: 2.6768\n","====== Epoch: 67\n","====> Validation loss: 2.6967,  X1 loss: 2.6875   X2 loss: 2.7059\n","====== Epoch: 68\n","====> Validation loss: 2.6982,  X1 loss: 2.6781   X2 loss: 2.7183\n","====== Epoch: 69\n","====> Validation loss: 2.6771,  X1 loss: 2.6648   X2 loss: 2.6893\n","====== Epoch: 70\n","====> Validation loss: 2.6809,  X1 loss: 2.6720   X2 loss: 2.6898\n","====== Epoch: 71\n","====> Validation loss: 2.6920,  X1 loss: 2.6770   X2 loss: 2.7071\n","====== Epoch: 72\n","====> Validation loss: 2.6492,  X1 loss: 2.6422   X2 loss: 2.6562\n","====== Epoch: 73\n","====> Validation loss: 2.6752,  X1 loss: 2.6651   X2 loss: 2.6853\n","====== Epoch: 74\n","====> Validation loss: 2.7126,  X1 loss: 2.6970   X2 loss: 2.7281\n","====== Epoch: 75\n","====> Validation loss: 2.6744,  X1 loss: 2.6668   X2 loss: 2.6820\n","====== Epoch: 76\n","====> Validation loss: 2.6843,  X1 loss: 2.6671   X2 loss: 2.7015\n","====== Epoch: 77\n","====> Validation loss: 2.6521,  X1 loss: 2.6406   X2 loss: 2.6636\n","====== Epoch: 78\n","====> Validation loss: 2.6871,  X1 loss: 2.6737   X2 loss: 2.7005\n","====== Epoch: 79\n","====> Validation loss: 2.6604,  X1 loss: 2.6458   X2 loss: 2.6750\n","====== Epoch: 80\n","====> Validation loss: 2.6201,  X1 loss: 2.6130   X2 loss: 2.6273\n","====== Epoch: 81\n","====> Validation loss: 2.6555,  X1 loss: 2.6418   X2 loss: 2.6693\n","====== Epoch: 82\n","====> Validation loss: 2.6157,  X1 loss: 2.6040   X2 loss: 2.6273\n","====== Epoch: 83\n","====> Validation loss: 2.6781,  X1 loss: 2.6607   X2 loss: 2.6955\n","====== Epoch: 84\n","====> Validation loss: 2.7002,  X1 loss: 2.6849   X2 loss: 2.7154\n","====== Epoch: 85\n","====> Validation loss: 2.6582,  X1 loss: 2.6402   X2 loss: 2.6762\n","====== Epoch: 86\n","====> Validation loss: 2.6520,  X1 loss: 2.6463   X2 loss: 2.6578\n","====== Epoch: 87\n","====> Validation loss: 2.6726,  X1 loss: 2.6570   X2 loss: 2.6881\n","====== Epoch: 88\n","====> Validation loss: 2.6527,  X1 loss: 2.6346   X2 loss: 2.6707\n","====== Epoch: 89\n","====> Validation loss: 2.6916,  X1 loss: 2.6714   X2 loss: 2.7118\n","====== Epoch: 90\n","====> Validation loss: 2.6431,  X1 loss: 2.6293   X2 loss: 2.6570\n","====== Epoch: 91\n","====> Validation loss: 2.6544,  X1 loss: 2.6383   X2 loss: 2.6704\n","====== Epoch: 92\n","====> Validation loss: 2.6474,  X1 loss: 2.6364   X2 loss: 2.6583\n","====== Epoch: 93\n","====> Validation loss: 2.6327,  X1 loss: 2.6200   X2 loss: 2.6455\n","====== Epoch: 94\n","====> Validation loss: 2.6481,  X1 loss: 2.6324   X2 loss: 2.6639\n","====== Epoch: 95\n","====> Validation loss: 2.6528,  X1 loss: 2.6332   X2 loss: 2.6724\n","====== Epoch: 96\n","====> Validation loss: 2.6968,  X1 loss: 2.6763   X2 loss: 2.7174\n","====== Epoch: 97\n","====> Validation loss: 2.6292,  X1 loss: 2.6122   X2 loss: 2.6463\n","====== Epoch: 98\n","====> Validation loss: 2.6670,  X1 loss: 2.6579   X2 loss: 2.6761\n","====== Epoch: 99\n","====> Validation loss: 2.6117,  X1 loss: 2.6049   X2 loss: 2.6186\n","====== Epoch: 100\n","====> Validation loss: 2.6251,  X1 loss: 2.6205   X2 loss: 2.6297\n","====== Epoch: 101\n","====> Validation loss: 2.6309,  X1 loss: 2.6139   X2 loss: 2.6479\n","====== Epoch: 102\n","====> Validation loss: 2.6362,  X1 loss: 2.6242   X2 loss: 2.6483\n","====== Epoch: 103\n","====> Validation loss: 2.6571,  X1 loss: 2.6427   X2 loss: 2.6715\n","====== Epoch: 104\n","====> Validation loss: 2.6343,  X1 loss: 2.6168   X2 loss: 2.6518\n","====== Epoch: 105\n","====> Validation loss: 2.6343,  X1 loss: 2.6174   X2 loss: 2.6511\n","====== Epoch: 106\n","====> Validation loss: 2.5954,  X1 loss: 2.5868   X2 loss: 2.6040\n","====== Epoch: 107\n","====> Validation loss: 2.6570,  X1 loss: 2.6426   X2 loss: 2.6714\n","====== Epoch: 108\n","====> Validation loss: 2.6381,  X1 loss: 2.6202   X2 loss: 2.6559\n","====== Epoch: 109\n","====> Validation loss: 2.6137,  X1 loss: 2.5941   X2 loss: 2.6334\n","====== Epoch: 110\n","====> Validation loss: 2.6150,  X1 loss: 2.5978   X2 loss: 2.6322\n","====== Epoch: 111\n","====> Validation loss: 2.6222,  X1 loss: 2.6113   X2 loss: 2.6330\n","====== Epoch: 112\n","====> Validation loss: 2.6267,  X1 loss: 2.6150   X2 loss: 2.6385\n","====== Epoch: 113\n","====> Validation loss: 2.5869,  X1 loss: 2.5757   X2 loss: 2.5980\n","====== Epoch: 114\n","====> Validation loss: 2.6229,  X1 loss: 2.6050   X2 loss: 2.6408\n","====== Epoch: 115\n","====> Validation loss: 2.6162,  X1 loss: 2.6030   X2 loss: 2.6294\n","====== Epoch: 116\n","====> Validation loss: 2.6179,  X1 loss: 2.6165   X2 loss: 2.6192\n","====== Epoch: 117\n","====> Validation loss: 2.6362,  X1 loss: 2.6231   X2 loss: 2.6493\n","====== Epoch: 118\n","====> Validation loss: 2.6225,  X1 loss: 2.6102   X2 loss: 2.6349\n","====== Epoch: 119\n","====> Validation loss: 2.6370,  X1 loss: 2.6301   X2 loss: 2.6438\n","====== Epoch: 120\n","====> Validation loss: 2.6369,  X1 loss: 2.6213   X2 loss: 2.6526\n","====== Epoch: 121\n","====> Validation loss: 2.6479,  X1 loss: 2.6338   X2 loss: 2.6620\n","====== Epoch: 122\n","====> Validation loss: 2.6060,  X1 loss: 2.5897   X2 loss: 2.6222\n","====== Epoch: 123\n","====> Validation loss: 2.6045,  X1 loss: 2.5847   X2 loss: 2.6243\n","====== Epoch: 124\n","====> Validation loss: 2.6007,  X1 loss: 2.5878   X2 loss: 2.6136\n","====== Epoch: 125\n","====> Validation loss: 2.5976,  X1 loss: 2.5881   X2 loss: 2.6072\n","====== Epoch: 126\n","====> Validation loss: 2.6240,  X1 loss: 2.6070   X2 loss: 2.6410\n","====== Epoch: 127\n","====> Validation loss: 2.6310,  X1 loss: 2.6127   X2 loss: 2.6493\n","====== Epoch: 128\n","====> Validation loss: 2.6212,  X1 loss: 2.6020   X2 loss: 2.6405\n","====== Epoch: 129\n","====> Validation loss: 2.6319,  X1 loss: 2.6171   X2 loss: 2.6467\n","====== Epoch: 130\n","====> Validation loss: 2.6245,  X1 loss: 2.6108   X2 loss: 2.6383\n","====== Epoch: 131\n","====> Validation loss: 2.6112,  X1 loss: 2.5935   X2 loss: 2.6288\n","====== Epoch: 132\n","====> Validation loss: 2.6349,  X1 loss: 2.6190   X2 loss: 2.6508\n","====== Epoch: 133\n","====> Validation loss: 2.6171,  X1 loss: 2.5999   X2 loss: 2.6342\n","====== Epoch: 134\n","====> Validation loss: 2.6230,  X1 loss: 2.6059   X2 loss: 2.6402\n","====== Epoch: 135\n","====> Validation loss: 2.6143,  X1 loss: 2.5882   X2 loss: 2.6404\n","====== Epoch: 136\n","====> Validation loss: 2.6392,  X1 loss: 2.6278   X2 loss: 2.6507\n","====== Epoch: 137\n","====> Validation loss: 2.6172,  X1 loss: 2.6037   X2 loss: 2.6306\n","====== Epoch: 138\n","====> Validation loss: 2.6052,  X1 loss: 2.5848   X2 loss: 2.6256\n","====== Epoch: 139\n","====> Validation loss: 2.6353,  X1 loss: 2.6154   X2 loss: 2.6552\n","====== Epoch: 140\n","====> Validation loss: 2.6363,  X1 loss: 2.6167   X2 loss: 2.6559\n","====== Epoch: 141\n","====> Validation loss: 2.6203,  X1 loss: 2.6104   X2 loss: 2.6302\n","====== Epoch: 142\n","====> Validation loss: 2.5954,  X1 loss: 2.5813   X2 loss: 2.6096\n","====== Epoch: 143\n","====> Validation loss: 2.6402,  X1 loss: 2.6288   X2 loss: 2.6516\n","====== Epoch: 144\n","====> Validation loss: 2.6264,  X1 loss: 2.6078   X2 loss: 2.6449\n","====== Epoch: 145\n","====> Validation loss: 2.5941,  X1 loss: 2.5838   X2 loss: 2.6044\n","====== Epoch: 146\n","====> Validation loss: 2.6317,  X1 loss: 2.6178   X2 loss: 2.6456\n","====== Epoch: 147\n","====> Validation loss: 2.5699,  X1 loss: 2.5531   X2 loss: 2.5868\n","====== Epoch: 148\n","====> Validation loss: 2.6150,  X1 loss: 2.6072   X2 loss: 2.6229\n","====== Epoch: 149\n","====> Validation loss: 2.5960,  X1 loss: 2.5765   X2 loss: 2.6155\n","====== Epoch: 150\n","====> Validation loss: 2.5959,  X1 loss: 2.5863   X2 loss: 2.6055\n","====== Epoch: 151\n","====> Validation loss: 2.6040,  X1 loss: 2.5905   X2 loss: 2.6176\n","====== Epoch: 152\n","====> Validation loss: 2.6524,  X1 loss: 2.6340   X2 loss: 2.6708\n","====== Epoch: 153\n","====> Validation loss: 2.6367,  X1 loss: 2.6230   X2 loss: 2.6503\n","====== Epoch: 154\n","====> Validation loss: 2.6423,  X1 loss: 2.6239   X2 loss: 2.6606\n","====== Epoch: 155\n","====> Validation loss: 2.6151,  X1 loss: 2.6016   X2 loss: 2.6287\n","====== Epoch: 156\n","====> Validation loss: 2.6077,  X1 loss: 2.5923   X2 loss: 2.6232\n","====== Epoch: 157\n","====> Validation loss: 2.6157,  X1 loss: 2.6077   X2 loss: 2.6237\n","====== Epoch: 158\n","====> Validation loss: 2.6295,  X1 loss: 2.6153   X2 loss: 2.6438\n","====== Epoch: 159\n","====> Validation loss: 2.5975,  X1 loss: 2.5831   X2 loss: 2.6119\n","====== Epoch: 160\n","====> Validation loss: 2.6195,  X1 loss: 2.6020   X2 loss: 2.6370\n","====== Epoch: 161\n","====> Validation loss: 2.6097,  X1 loss: 2.5916   X2 loss: 2.6279\n","====== Epoch: 162\n","====> Validation loss: 2.6145,  X1 loss: 2.6036   X2 loss: 2.6255\n","====== Epoch: 163\n","====> Validation loss: 2.6072,  X1 loss: 2.5925   X2 loss: 2.6218\n","====== Epoch: 164\n","====> Validation loss: 2.6114,  X1 loss: 2.5914   X2 loss: 2.6313\n","====== Epoch: 165\n","====> Validation loss: 2.6178,  X1 loss: 2.6048   X2 loss: 2.6307\n","====== Epoch: 166\n","====> Validation loss: 2.6054,  X1 loss: 2.5929   X2 loss: 2.6180\n","====== Epoch: 167\n","====> Validation loss: 2.6027,  X1 loss: 2.5985   X2 loss: 2.6070\n","====== Epoch: 168\n","====> Validation loss: 2.5947,  X1 loss: 2.5753   X2 loss: 2.6140\n","====== Epoch: 169\n","====> Validation loss: 2.6232,  X1 loss: 2.6018   X2 loss: 2.6445\n","====== Epoch: 170\n","====> Validation loss: 2.6085,  X1 loss: 2.5916   X2 loss: 2.6254\n","====== Epoch: 171\n","====> Validation loss: 2.5809,  X1 loss: 2.5680   X2 loss: 2.5937\n","====== Epoch: 172\n","====> Validation loss: 2.5712,  X1 loss: 2.5555   X2 loss: 2.5869\n","====== Epoch: 173\n","====> Validation loss: 2.6259,  X1 loss: 2.6115   X2 loss: 2.6402\n","====== Epoch: 174\n","====> Validation loss: 2.5964,  X1 loss: 2.5831   X2 loss: 2.6098\n","====== Epoch: 175\n","====> Validation loss: 2.6028,  X1 loss: 2.5861   X2 loss: 2.6195\n","====== Epoch: 176\n","====> Validation loss: 2.6441,  X1 loss: 2.6356   X2 loss: 2.6526\n","====== Epoch: 177\n","====> Validation loss: 2.5893,  X1 loss: 2.5760   X2 loss: 2.6025\n","====== Epoch: 178\n","====> Validation loss: 2.5821,  X1 loss: 2.5770   X2 loss: 2.5872\n","====== Epoch: 179\n","====> Validation loss: 2.5930,  X1 loss: 2.5875   X2 loss: 2.5985\n","====== Epoch: 180\n","====> Validation loss: 2.5758,  X1 loss: 2.5588   X2 loss: 2.5928\n","====== Epoch: 181\n","====> Validation loss: 2.6044,  X1 loss: 2.5919   X2 loss: 2.6169\n","====== Epoch: 182\n","====> Validation loss: 2.6083,  X1 loss: 2.5909   X2 loss: 2.6257\n","====== Epoch: 183\n","====> Validation loss: 2.6013,  X1 loss: 2.5877   X2 loss: 2.6149\n","====== Epoch: 184\n","====> Validation loss: 2.6359,  X1 loss: 2.6159   X2 loss: 2.6559\n","====== Epoch: 185\n","====> Validation loss: 2.6368,  X1 loss: 2.6189   X2 loss: 2.6547\n","====== Epoch: 186\n","====> Validation loss: 2.6347,  X1 loss: 2.6187   X2 loss: 2.6506\n","====== Epoch: 187\n","====> Validation loss: 2.5694,  X1 loss: 2.5522   X2 loss: 2.5867\n","====== Epoch: 188\n","====> Validation loss: 2.6073,  X1 loss: 2.5860   X2 loss: 2.6287\n","====== Epoch: 189\n","====> Validation loss: 2.6076,  X1 loss: 2.5928   X2 loss: 2.6225\n","====== Epoch: 190\n","====> Validation loss: 2.5903,  X1 loss: 2.5897   X2 loss: 2.5909\n","====== Epoch: 191\n","====> Validation loss: 2.5585,  X1 loss: 2.5440   X2 loss: 2.5730\n","====== Epoch: 192\n","====> Validation loss: 2.6151,  X1 loss: 2.5946   X2 loss: 2.6357\n","====== Epoch: 193\n","====> Validation loss: 2.5806,  X1 loss: 2.5618   X2 loss: 2.5994\n","====== Epoch: 194\n","====> Validation loss: 2.6243,  X1 loss: 2.6143   X2 loss: 2.6342\n","====== Epoch: 195\n","====> Validation loss: 2.5770,  X1 loss: 2.5646   X2 loss: 2.5894\n","====== Epoch: 196\n","====> Validation loss: 2.6280,  X1 loss: 2.6138   X2 loss: 2.6423\n","====== Epoch: 197\n","====> Validation loss: 2.5781,  X1 loss: 2.5574   X2 loss: 2.5988\n","====== Epoch: 198\n","====> Validation loss: 2.5966,  X1 loss: 2.5736   X2 loss: 2.6197\n","====== Epoch: 199\n","====> Validation loss: 2.6130,  X1 loss: 2.6026   X2 loss: 2.6235\n","====== Epoch: 200\n","====> Validation loss: 2.6157,  X1 loss: 2.6043   X2 loss: 2.6271\n","====== Epoch: 201\n","====> Validation loss: 2.5651,  X1 loss: 2.5518   X2 loss: 2.5784\n","====== Epoch: 202\n","====> Validation loss: 2.5995,  X1 loss: 2.5832   X2 loss: 2.6158\n","====== Epoch: 203\n","====> Validation loss: 2.6463,  X1 loss: 2.6312   X2 loss: 2.6614\n","====== Epoch: 204\n","====> Validation loss: 2.5941,  X1 loss: 2.5773   X2 loss: 2.6108\n","====== Epoch: 205\n","====> Validation loss: 2.5852,  X1 loss: 2.5740   X2 loss: 2.5964\n","====== Epoch: 206\n","====> Validation loss: 2.6333,  X1 loss: 2.6243   X2 loss: 2.6423\n","====== Epoch: 207\n","====> Validation loss: 2.6198,  X1 loss: 2.6036   X2 loss: 2.6360\n","====== Epoch: 208\n","====> Validation loss: 2.5780,  X1 loss: 2.5667   X2 loss: 2.5893\n","====== Epoch: 209\n","====> Validation loss: 2.6219,  X1 loss: 2.6038   X2 loss: 2.6400\n","====== Epoch: 210\n","====> Validation loss: 2.5819,  X1 loss: 2.5736   X2 loss: 2.5902\n","====== Epoch: 211\n","====> Validation loss: 2.6033,  X1 loss: 2.5878   X2 loss: 2.6188\n","====== Epoch: 212\n","====> Validation loss: 2.6104,  X1 loss: 2.5996   X2 loss: 2.6213\n","====== Epoch: 213\n","====> Validation loss: 2.5996,  X1 loss: 2.5823   X2 loss: 2.6168\n","====== Epoch: 214\n","====> Validation loss: 2.6101,  X1 loss: 2.5893   X2 loss: 2.6309\n","====== Epoch: 215\n","====> Validation loss: 2.5603,  X1 loss: 2.5516   X2 loss: 2.5690\n","====== Epoch: 216\n","====> Validation loss: 2.5653,  X1 loss: 2.5616   X2 loss: 2.5690\n","====== Epoch: 217\n","====> Validation loss: 2.6036,  X1 loss: 2.5827   X2 loss: 2.6245\n","====== Epoch: 218\n","====> Validation loss: 2.5755,  X1 loss: 2.5660   X2 loss: 2.5850\n","====== Epoch: 219\n","====> Validation loss: 2.6044,  X1 loss: 2.5877   X2 loss: 2.6212\n","====== Epoch: 220\n","====> Validation loss: 2.5915,  X1 loss: 2.5668   X2 loss: 2.6162\n","====== Epoch: 221\n","====> Validation loss: 2.5784,  X1 loss: 2.5585   X2 loss: 2.5984\n","====== Epoch: 222\n","====> Validation loss: 2.5463,  X1 loss: 2.5337   X2 loss: 2.5588\n","====== Epoch: 223\n","====> Validation loss: 2.6009,  X1 loss: 2.5893   X2 loss: 2.6125\n","====== Epoch: 224\n","====> Validation loss: 2.5950,  X1 loss: 2.5779   X2 loss: 2.6122\n","====== Epoch: 225\n","====> Validation loss: 2.5561,  X1 loss: 2.5405   X2 loss: 2.5718\n","====== Epoch: 226\n","====> Validation loss: 2.6127,  X1 loss: 2.5953   X2 loss: 2.6301\n","====== Epoch: 227\n","====> Validation loss: 2.5862,  X1 loss: 2.5735   X2 loss: 2.5989\n","====== Epoch: 228\n","====> Validation loss: 2.6092,  X1 loss: 2.5983   X2 loss: 2.6201\n","====== Epoch: 229\n","====> Validation loss: 2.5761,  X1 loss: 2.5531   X2 loss: 2.5991\n","====== Epoch: 230\n","====> Validation loss: 2.6120,  X1 loss: 2.5942   X2 loss: 2.6299\n","====== Epoch: 231\n","====> Validation loss: 2.5918,  X1 loss: 2.5811   X2 loss: 2.6025\n","====== Epoch: 232\n","====> Validation loss: 2.5652,  X1 loss: 2.5542   X2 loss: 2.5761\n","====== Epoch: 233\n","====> Validation loss: 2.6025,  X1 loss: 2.5850   X2 loss: 2.6200\n","====== Epoch: 234\n","====> Validation loss: 2.6190,  X1 loss: 2.6008   X2 loss: 2.6373\n","====== Epoch: 235\n","====> Validation loss: 2.5673,  X1 loss: 2.5416   X2 loss: 2.5930\n","====== Epoch: 236\n","====> Validation loss: 2.5868,  X1 loss: 2.5732   X2 loss: 2.6004\n","====== Epoch: 237\n","====> Validation loss: 2.5787,  X1 loss: 2.5614   X2 loss: 2.5959\n","====== Epoch: 238\n","====> Validation loss: 2.5584,  X1 loss: 2.5413   X2 loss: 2.5754\n","====== Epoch: 239\n","====> Validation loss: 2.6139,  X1 loss: 2.5971   X2 loss: 2.6307\n","====== Epoch: 240\n","====> Validation loss: 2.5825,  X1 loss: 2.5655   X2 loss: 2.5996\n","====== Epoch: 241\n","====> Validation loss: 2.5771,  X1 loss: 2.5634   X2 loss: 2.5909\n","====== Epoch: 242\n","====> Validation loss: 2.6118,  X1 loss: 2.5944   X2 loss: 2.6292\n","====== Epoch: 243\n","====> Validation loss: 2.5803,  X1 loss: 2.5707   X2 loss: 2.5898\n","====== Epoch: 244\n","====> Validation loss: 2.5880,  X1 loss: 2.5737   X2 loss: 2.6022\n","====== Epoch: 245\n","====> Validation loss: 2.6165,  X1 loss: 2.6080   X2 loss: 2.6250\n","====== Epoch: 246\n","====> Validation loss: 2.5525,  X1 loss: 2.5448   X2 loss: 2.5601\n","====== Epoch: 247\n","====> Validation loss: 2.6061,  X1 loss: 2.5939   X2 loss: 2.6182\n","====== Epoch: 248\n","====> Validation loss: 2.5736,  X1 loss: 2.5577   X2 loss: 2.5895\n","====== Epoch: 249\n","====> Validation loss: 2.5843,  X1 loss: 2.5612   X2 loss: 2.6074\n","====== Epoch: 250\n","====> Validation loss: 2.5880,  X1 loss: 2.5680   X2 loss: 2.6080\n","====== Epoch: 251\n","====> Validation loss: 2.5897,  X1 loss: 2.5655   X2 loss: 2.6139\n","====== Epoch: 252\n","====> Validation loss: 2.5607,  X1 loss: 2.5416   X2 loss: 2.5798\n","====== Epoch: 253\n","====> Validation loss: 2.6028,  X1 loss: 2.5929   X2 loss: 2.6127\n","====== Epoch: 254\n","====> Validation loss: 2.6021,  X1 loss: 2.5857   X2 loss: 2.6184\n","====== Epoch: 255\n","====> Validation loss: 2.5951,  X1 loss: 2.5827   X2 loss: 2.6074\n","====== Epoch: 256\n","====> Validation loss: 2.5797,  X1 loss: 2.5657   X2 loss: 2.5937\n","====== Epoch: 257\n","====> Validation loss: 2.6069,  X1 loss: 2.5882   X2 loss: 2.6256\n","====== Epoch: 258\n","====> Validation loss: 2.6076,  X1 loss: 2.5866   X2 loss: 2.6286\n","====== Epoch: 259\n","====> Validation loss: 2.5791,  X1 loss: 2.5645   X2 loss: 2.5937\n","====== Epoch: 260\n","====> Validation loss: 2.5767,  X1 loss: 2.5582   X2 loss: 2.5952\n","====== Epoch: 261\n","====> Validation loss: 2.5675,  X1 loss: 2.5554   X2 loss: 2.5796\n","====== Epoch: 262\n","====> Validation loss: 2.5688,  X1 loss: 2.5489   X2 loss: 2.5886\n","====== Epoch: 263\n","====> Validation loss: 2.6053,  X1 loss: 2.5842   X2 loss: 2.6265\n","====== Epoch: 264\n","====> Validation loss: 2.5919,  X1 loss: 2.5679   X2 loss: 2.6159\n","====== Epoch: 265\n","====> Validation loss: 2.5855,  X1 loss: 2.5713   X2 loss: 2.5997\n","====== Epoch: 266\n","====> Validation loss: 2.5834,  X1 loss: 2.5679   X2 loss: 2.5989\n","====== Epoch: 267\n","====> Validation loss: 2.6114,  X1 loss: 2.5976   X2 loss: 2.6251\n","====== Epoch: 268\n","====> Validation loss: 2.5630,  X1 loss: 2.5477   X2 loss: 2.5783\n","====== Epoch: 269\n","====> Validation loss: 2.5547,  X1 loss: 2.5338   X2 loss: 2.5757\n","====== Epoch: 270\n","====> Validation loss: 2.6002,  X1 loss: 2.5794   X2 loss: 2.6210\n","====== Epoch: 271\n","====> Validation loss: 2.5832,  X1 loss: 2.5755   X2 loss: 2.5909\n","====== Epoch: 272\n","====> Validation loss: 2.5874,  X1 loss: 2.5758   X2 loss: 2.5991\n","====== Epoch: 273\n","====> Validation loss: 2.5599,  X1 loss: 2.5437   X2 loss: 2.5760\n","====== Epoch: 274\n","====> Validation loss: 2.5737,  X1 loss: 2.5573   X2 loss: 2.5902\n","====== Epoch: 275\n","====> Validation loss: 2.5831,  X1 loss: 2.5707   X2 loss: 2.5956\n","====== Epoch: 276\n","====> Validation loss: 2.5745,  X1 loss: 2.5632   X2 loss: 2.5857\n","====== Epoch: 277\n","====> Validation loss: 2.5811,  X1 loss: 2.5737   X2 loss: 2.5885\n","====== Epoch: 278\n","====> Validation loss: 2.6030,  X1 loss: 2.5874   X2 loss: 2.6186\n","====== Epoch: 279\n","====> Validation loss: 2.5848,  X1 loss: 2.5665   X2 loss: 2.6031\n","====== Epoch: 280\n","====> Validation loss: 2.5659,  X1 loss: 2.5545   X2 loss: 2.5774\n","====== Epoch: 281\n","====> Validation loss: 2.6171,  X1 loss: 2.5940   X2 loss: 2.6402\n","====== Epoch: 282\n","====> Validation loss: 2.5945,  X1 loss: 2.5812   X2 loss: 2.6078\n","====== Epoch: 283\n","====> Validation loss: 2.5649,  X1 loss: 2.5529   X2 loss: 2.5770\n","====== Epoch: 284\n","====> Validation loss: 2.6105,  X1 loss: 2.5856   X2 loss: 2.6355\n","====== Epoch: 285\n","====> Validation loss: 2.5421,  X1 loss: 2.5254   X2 loss: 2.5588\n","====== Epoch: 286\n","====> Validation loss: 2.5658,  X1 loss: 2.5536   X2 loss: 2.5781\n","====== Epoch: 287\n","====> Validation loss: 2.5759,  X1 loss: 2.5630   X2 loss: 2.5888\n","====== Epoch: 288\n","====> Validation loss: 2.5609,  X1 loss: 2.5416   X2 loss: 2.5803\n","====== Epoch: 289\n","====> Validation loss: 2.5791,  X1 loss: 2.5600   X2 loss: 2.5981\n","====== Epoch: 290\n","====> Validation loss: 2.5729,  X1 loss: 2.5563   X2 loss: 2.5896\n","====== Epoch: 291\n","====> Validation loss: 2.5960,  X1 loss: 2.5793   X2 loss: 2.6127\n","====== Epoch: 292\n","====> Validation loss: 2.5632,  X1 loss: 2.5397   X2 loss: 2.5866\n","====== Epoch: 293\n","====> Validation loss: 2.5927,  X1 loss: 2.5816   X2 loss: 2.6037\n","====== Epoch: 294\n","====> Validation loss: 2.6056,  X1 loss: 2.5923   X2 loss: 2.6190\n","====== Epoch: 295\n","====> Validation loss: 2.5645,  X1 loss: 2.5532   X2 loss: 2.5759\n","====== Epoch: 296\n","====> Validation loss: 2.5719,  X1 loss: 2.5605   X2 loss: 2.5833\n","====== Epoch: 297\n","====> Validation loss: 2.5778,  X1 loss: 2.5710   X2 loss: 2.5846\n","====== Epoch: 298\n","====> Validation loss: 2.5724,  X1 loss: 2.5614   X2 loss: 2.5833\n","====== Epoch: 299\n","====> Validation loss: 2.5883,  X1 loss: 2.5632   X2 loss: 2.6134\n","+--------------New model: eeg0lin_env2conv0lin----------------------+\n","====== Epoch: 1\n","====> Validation loss: 3.1749,  X1 loss: 3.1724   X2 loss: 3.1774\n","====== Epoch: 2\n","====> Validation loss: 3.1042,  X1 loss: 3.0981   X2 loss: 3.1103\n","====== Epoch: 3\n","====> Validation loss: 3.0171,  X1 loss: 3.0202   X2 loss: 3.0140\n","====== Epoch: 4\n","====> Validation loss: 3.0012,  X1 loss: 2.9954   X2 loss: 3.0069\n","====== Epoch: 5\n","====> Validation loss: 3.0007,  X1 loss: 2.9991   X2 loss: 3.0024\n","====== Epoch: 6\n","====> Validation loss: 2.9570,  X1 loss: 2.9517   X2 loss: 2.9624\n","====== Epoch: 7\n","====> Validation loss: 2.9178,  X1 loss: 2.9116   X2 loss: 2.9239\n","====== Epoch: 8\n","====> Validation loss: 2.9134,  X1 loss: 2.9063   X2 loss: 2.9205\n","====== Epoch: 9\n","====> Validation loss: 2.9354,  X1 loss: 2.9291   X2 loss: 2.9416\n","====== Epoch: 10\n","====> Validation loss: 2.9249,  X1 loss: 2.9167   X2 loss: 2.9332\n","====== Epoch: 11\n","====> Validation loss: 2.8863,  X1 loss: 2.8774   X2 loss: 2.8953\n","====== Epoch: 12\n","====> Validation loss: 2.8723,  X1 loss: 2.8644   X2 loss: 2.8802\n","====== Epoch: 13\n","====> Validation loss: 2.8228,  X1 loss: 2.8132   X2 loss: 2.8325\n","====== Epoch: 14\n","====> Validation loss: 2.8494,  X1 loss: 2.8443   X2 loss: 2.8545\n","====== Epoch: 15\n","====> Validation loss: 2.8728,  X1 loss: 2.8555   X2 loss: 2.8901\n","====== Epoch: 16\n","====> Validation loss: 2.8199,  X1 loss: 2.8067   X2 loss: 2.8331\n","====== Epoch: 17\n","====> Validation loss: 2.8092,  X1 loss: 2.8023   X2 loss: 2.8161\n","====== Epoch: 18\n","====> Validation loss: 2.8213,  X1 loss: 2.8122   X2 loss: 2.8303\n","====== Epoch: 19\n","====> Validation loss: 2.8382,  X1 loss: 2.8269   X2 loss: 2.8496\n","====== Epoch: 20\n","====> Validation loss: 2.8431,  X1 loss: 2.8256   X2 loss: 2.8606\n","====== Epoch: 21\n","====> Validation loss: 2.7966,  X1 loss: 2.7858   X2 loss: 2.8074\n","====== Epoch: 22\n","====> Validation loss: 2.7962,  X1 loss: 2.7886   X2 loss: 2.8038\n","====== Epoch: 23\n","====> Validation loss: 2.7992,  X1 loss: 2.7828   X2 loss: 2.8156\n","====== Epoch: 24\n","====> Validation loss: 2.8126,  X1 loss: 2.7997   X2 loss: 2.8255\n","====== Epoch: 25\n","====> Validation loss: 2.7811,  X1 loss: 2.7688   X2 loss: 2.7934\n","====== Epoch: 26\n","====> Validation loss: 2.8132,  X1 loss: 2.8079   X2 loss: 2.8186\n","====== Epoch: 27\n","====> Validation loss: 2.8014,  X1 loss: 2.7918   X2 loss: 2.8109\n","====== Epoch: 28\n","====> Validation loss: 2.8052,  X1 loss: 2.7896   X2 loss: 2.8208\n","====== Epoch: 29\n","====> Validation loss: 2.8185,  X1 loss: 2.8055   X2 loss: 2.8315\n","====== Epoch: 30\n","====> Validation loss: 2.7804,  X1 loss: 2.7606   X2 loss: 2.8002\n","====== Epoch: 31\n","====> Validation loss: 2.8240,  X1 loss: 2.8109   X2 loss: 2.8372\n","====== Epoch: 32\n","====> Validation loss: 2.8106,  X1 loss: 2.8014   X2 loss: 2.8198\n","====== Epoch: 33\n","====> Validation loss: 2.8003,  X1 loss: 2.7864   X2 loss: 2.8142\n","====== Epoch: 34\n","====> Validation loss: 2.8082,  X1 loss: 2.7911   X2 loss: 2.8253\n","====== Epoch: 35\n","====> Validation loss: 2.7891,  X1 loss: 2.7760   X2 loss: 2.8022\n","====== Epoch: 36\n","====> Validation loss: 2.7473,  X1 loss: 2.7389   X2 loss: 2.7557\n","====== Epoch: 37\n","====> Validation loss: 2.7842,  X1 loss: 2.7736   X2 loss: 2.7947\n","====== Epoch: 38\n","====> Validation loss: 2.7840,  X1 loss: 2.7739   X2 loss: 2.7940\n","====== Epoch: 39\n","====> Validation loss: 2.7859,  X1 loss: 2.7755   X2 loss: 2.7963\n","====== Epoch: 40\n","====> Validation loss: 2.7647,  X1 loss: 2.7532   X2 loss: 2.7762\n","====== Epoch: 41\n","====> Validation loss: 2.7915,  X1 loss: 2.7746   X2 loss: 2.8085\n","====== Epoch: 42\n","====> Validation loss: 2.7767,  X1 loss: 2.7708   X2 loss: 2.7826\n","====== Epoch: 43\n","====> Validation loss: 2.8022,  X1 loss: 2.7899   X2 loss: 2.8146\n","====== Epoch: 44\n","====> Validation loss: 2.7784,  X1 loss: 2.7679   X2 loss: 2.7889\n","====== Epoch: 45\n","====> Validation loss: 2.7576,  X1 loss: 2.7465   X2 loss: 2.7688\n","====== Epoch: 46\n","====> Validation loss: 2.8322,  X1 loss: 2.8110   X2 loss: 2.8533\n","====== Epoch: 47\n","====> Validation loss: 2.8213,  X1 loss: 2.8121   X2 loss: 2.8306\n","====== Epoch: 48\n","====> Validation loss: 2.8016,  X1 loss: 2.7889   X2 loss: 2.8142\n","====== Epoch: 49\n","====> Validation loss: 2.8303,  X1 loss: 2.8194   X2 loss: 2.8412\n","====== Epoch: 50\n","====> Validation loss: 2.7891,  X1 loss: 2.7792   X2 loss: 2.7990\n","====== Epoch: 51\n","====> Validation loss: 2.8087,  X1 loss: 2.7914   X2 loss: 2.8259\n","====== Epoch: 52\n","====> Validation loss: 2.8196,  X1 loss: 2.8155   X2 loss: 2.8237\n","====== Epoch: 53\n","====> Validation loss: 2.8066,  X1 loss: 2.8027   X2 loss: 2.8105\n","====== Epoch: 54\n","====> Validation loss: 2.7686,  X1 loss: 2.7606   X2 loss: 2.7767\n","====== Epoch: 55\n","====> Validation loss: 2.8440,  X1 loss: 2.8338   X2 loss: 2.8542\n","====== Epoch: 56\n","====> Validation loss: 2.7936,  X1 loss: 2.7788   X2 loss: 2.8084\n","====== Epoch: 57\n","====> Validation loss: 2.8364,  X1 loss: 2.8244   X2 loss: 2.8483\n","====== Epoch: 58\n","====> Validation loss: 2.7999,  X1 loss: 2.7839   X2 loss: 2.8160\n","====== Epoch: 59\n","====> Validation loss: 2.7817,  X1 loss: 2.7705   X2 loss: 2.7929\n","====== Epoch: 60\n","====> Validation loss: 2.8027,  X1 loss: 2.7905   X2 loss: 2.8148\n","====== Epoch: 61\n","====> Validation loss: 2.7955,  X1 loss: 2.7839   X2 loss: 2.8071\n","====== Epoch: 62\n","====> Validation loss: 2.8145,  X1 loss: 2.8003   X2 loss: 2.8288\n","====== Epoch: 63\n","====> Validation loss: 2.8159,  X1 loss: 2.8049   X2 loss: 2.8270\n","====== Epoch: 64\n","====> Validation loss: 2.8202,  X1 loss: 2.8106   X2 loss: 2.8298\n","====== Epoch: 65\n","====> Validation loss: 2.7885,  X1 loss: 2.7783   X2 loss: 2.7986\n","====== Epoch: 66\n","====> Validation loss: 2.7595,  X1 loss: 2.7547   X2 loss: 2.7643\n","====== Epoch: 67\n","====> Validation loss: 2.7761,  X1 loss: 2.7588   X2 loss: 2.7934\n","====== Epoch: 68\n","====> Validation loss: 2.8289,  X1 loss: 2.8190   X2 loss: 2.8387\n","====== Epoch: 69\n","====> Validation loss: 2.7471,  X1 loss: 2.7353   X2 loss: 2.7589\n","====== Epoch: 70\n","====> Validation loss: 2.8012,  X1 loss: 2.7820   X2 loss: 2.8205\n","====== Epoch: 71\n","====> Validation loss: 2.7768,  X1 loss: 2.7755   X2 loss: 2.7782\n","====== Epoch: 72\n","====> Validation loss: 2.7955,  X1 loss: 2.7862   X2 loss: 2.8048\n","====== Epoch: 73\n","====> Validation loss: 2.7819,  X1 loss: 2.7710   X2 loss: 2.7928\n","====== Epoch: 74\n","====> Validation loss: 2.8369,  X1 loss: 2.8247   X2 loss: 2.8491\n","====== Epoch: 75\n","====> Validation loss: 2.7531,  X1 loss: 2.7319   X2 loss: 2.7742\n","====== Epoch: 76\n","====> Validation loss: 2.8186,  X1 loss: 2.8106   X2 loss: 2.8267\n","====== Epoch: 77\n","====> Validation loss: 2.7767,  X1 loss: 2.7612   X2 loss: 2.7923\n","====== Epoch: 78\n","====> Validation loss: 2.7741,  X1 loss: 2.7611   X2 loss: 2.7872\n","====== Epoch: 79\n","====> Validation loss: 2.8025,  X1 loss: 2.7964   X2 loss: 2.8086\n","====== Epoch: 80\n","====> Validation loss: 2.8062,  X1 loss: 2.7991   X2 loss: 2.8132\n","====== Epoch: 81\n","====> Validation loss: 2.8041,  X1 loss: 2.7937   X2 loss: 2.8145\n","====== Epoch: 82\n","====> Validation loss: 2.8016,  X1 loss: 2.7854   X2 loss: 2.8178\n","====== Epoch: 83\n","====> Validation loss: 2.8049,  X1 loss: 2.7977   X2 loss: 2.8120\n","====== Epoch: 84\n","====> Validation loss: 2.7707,  X1 loss: 2.7496   X2 loss: 2.7918\n","====== Epoch: 85\n","====> Validation loss: 2.8261,  X1 loss: 2.8124   X2 loss: 2.8398\n","====== Epoch: 86\n","====> Validation loss: 2.7852,  X1 loss: 2.7693   X2 loss: 2.8011\n","====== Epoch: 87\n","====> Validation loss: 2.7767,  X1 loss: 2.7596   X2 loss: 2.7938\n","====== Epoch: 88\n","====> Validation loss: 2.8146,  X1 loss: 2.8027   X2 loss: 2.8264\n","====== Epoch: 89\n","====> Validation loss: 2.8198,  X1 loss: 2.8033   X2 loss: 2.8364\n","====== Epoch: 90\n","====> Validation loss: 2.7761,  X1 loss: 2.7696   X2 loss: 2.7825\n","====== Epoch: 91\n","====> Validation loss: 2.7859,  X1 loss: 2.7763   X2 loss: 2.7955\n","====== Epoch: 92\n","====> Validation loss: 2.7835,  X1 loss: 2.7652   X2 loss: 2.8018\n","====== Epoch: 93\n","====> Validation loss: 2.7809,  X1 loss: 2.7694   X2 loss: 2.7924\n","====== Epoch: 94\n","====> Validation loss: 2.7539,  X1 loss: 2.7400   X2 loss: 2.7678\n","====== Epoch: 95\n","====> Validation loss: 2.7821,  X1 loss: 2.7702   X2 loss: 2.7939\n","====== Epoch: 96\n","====> Validation loss: 2.7832,  X1 loss: 2.7623   X2 loss: 2.8041\n","====== Epoch: 97\n","====> Validation loss: 2.7841,  X1 loss: 2.7658   X2 loss: 2.8025\n","====== Epoch: 98\n","====> Validation loss: 2.7599,  X1 loss: 2.7512   X2 loss: 2.7685\n","====== Epoch: 99\n","====> Validation loss: 2.8019,  X1 loss: 2.7890   X2 loss: 2.8149\n","====== Epoch: 100\n","====> Validation loss: 2.8195,  X1 loss: 2.8018   X2 loss: 2.8372\n","====== Epoch: 101\n","====> Validation loss: 2.7947,  X1 loss: 2.7807   X2 loss: 2.8087\n","====== Epoch: 102\n","====> Validation loss: 2.7954,  X1 loss: 2.7746   X2 loss: 2.8161\n","====== Epoch: 103\n","====> Validation loss: 2.7744,  X1 loss: 2.7636   X2 loss: 2.7852\n","====== Epoch: 104\n","====> Validation loss: 2.8000,  X1 loss: 2.7935   X2 loss: 2.8064\n","====== Epoch: 105\n","====> Validation loss: 2.8157,  X1 loss: 2.8096   X2 loss: 2.8218\n","====== Epoch: 106\n","====> Validation loss: 2.7582,  X1 loss: 2.7428   X2 loss: 2.7737\n","====== Epoch: 107\n","====> Validation loss: 2.7648,  X1 loss: 2.7497   X2 loss: 2.7800\n","====== Epoch: 108\n","====> Validation loss: 2.7799,  X1 loss: 2.7659   X2 loss: 2.7939\n","====== Epoch: 109\n","====> Validation loss: 2.7589,  X1 loss: 2.7453   X2 loss: 2.7726\n","====== Epoch: 110\n","====> Validation loss: 2.7730,  X1 loss: 2.7586   X2 loss: 2.7875\n","====== Epoch: 111\n","====> Validation loss: 2.7558,  X1 loss: 2.7357   X2 loss: 2.7760\n","====== Epoch: 112\n","====> Validation loss: 2.7748,  X1 loss: 2.7655   X2 loss: 2.7840\n","====== Epoch: 113\n","====> Validation loss: 2.7496,  X1 loss: 2.7399   X2 loss: 2.7594\n","====== Epoch: 114\n","====> Validation loss: 2.7492,  X1 loss: 2.7444   X2 loss: 2.7540\n","====== Epoch: 115\n","====> Validation loss: 2.7748,  X1 loss: 2.7501   X2 loss: 2.7995\n","====== Epoch: 116\n","====> Validation loss: 2.7569,  X1 loss: 2.7425   X2 loss: 2.7712\n","====== Epoch: 117\n","====> Validation loss: 2.7594,  X1 loss: 2.7481   X2 loss: 2.7707\n","====== Epoch: 118\n","====> Validation loss: 2.7629,  X1 loss: 2.7491   X2 loss: 2.7767\n","====== Epoch: 119\n","====> Validation loss: 2.7726,  X1 loss: 2.7546   X2 loss: 2.7907\n","====== Epoch: 120\n","====> Validation loss: 2.7832,  X1 loss: 2.7693   X2 loss: 2.7972\n","====== Epoch: 121\n","====> Validation loss: 2.7817,  X1 loss: 2.7713   X2 loss: 2.7920\n","====== Epoch: 122\n","====> Validation loss: 2.7965,  X1 loss: 2.7918   X2 loss: 2.8012\n","====== Epoch: 123\n","====> Validation loss: 2.7704,  X1 loss: 2.7564   X2 loss: 2.7845\n","====== Epoch: 124\n","====> Validation loss: 2.7837,  X1 loss: 2.7717   X2 loss: 2.7957\n","====== Epoch: 125\n","====> Validation loss: 2.7488,  X1 loss: 2.7336   X2 loss: 2.7641\n","====== Epoch: 126\n","====> Validation loss: 2.7953,  X1 loss: 2.7795   X2 loss: 2.8111\n","====== Epoch: 127\n","====> Validation loss: 2.7738,  X1 loss: 2.7628   X2 loss: 2.7848\n","====== Epoch: 128\n","====> Validation loss: 2.7894,  X1 loss: 2.7719   X2 loss: 2.8068\n","====== Epoch: 129\n","====> Validation loss: 2.7724,  X1 loss: 2.7656   X2 loss: 2.7791\n","====== Epoch: 130\n","====> Validation loss: 2.7547,  X1 loss: 2.7467   X2 loss: 2.7626\n","====== Epoch: 131\n","====> Validation loss: 2.7784,  X1 loss: 2.7554   X2 loss: 2.8014\n","====== Epoch: 132\n","====> Validation loss: 2.7826,  X1 loss: 2.7688   X2 loss: 2.7964\n","====== Epoch: 133\n","====> Validation loss: 2.7506,  X1 loss: 2.7407   X2 loss: 2.7605\n","====== Epoch: 134\n","====> Validation loss: 2.7376,  X1 loss: 2.7167   X2 loss: 2.7585\n","====== Epoch: 135\n","====> Validation loss: 2.7554,  X1 loss: 2.7351   X2 loss: 2.7758\n","====== Epoch: 136\n","====> Validation loss: 2.7538,  X1 loss: 2.7411   X2 loss: 2.7665\n","====== Epoch: 137\n","====> Validation loss: 2.7795,  X1 loss: 2.7736   X2 loss: 2.7855\n","====== Epoch: 138\n","====> Validation loss: 2.7875,  X1 loss: 2.7751   X2 loss: 2.7999\n","====== Epoch: 139\n","====> Validation loss: 2.7774,  X1 loss: 2.7674   X2 loss: 2.7874\n","====== Epoch: 140\n","====> Validation loss: 2.7761,  X1 loss: 2.7611   X2 loss: 2.7912\n","====== Epoch: 141\n","====> Validation loss: 2.7481,  X1 loss: 2.7309   X2 loss: 2.7652\n","====== Epoch: 142\n","====> Validation loss: 2.8054,  X1 loss: 2.7969   X2 loss: 2.8139\n","====== Epoch: 143\n","====> Validation loss: 2.7565,  X1 loss: 2.7442   X2 loss: 2.7687\n","====== Epoch: 144\n","====> Validation loss: 2.8062,  X1 loss: 2.7908   X2 loss: 2.8216\n","====== Epoch: 145\n","====> Validation loss: 2.7515,  X1 loss: 2.7481   X2 loss: 2.7550\n","====== Epoch: 146\n","====> Validation loss: 2.7892,  X1 loss: 2.7739   X2 loss: 2.8045\n","====== Epoch: 147\n","====> Validation loss: 2.7881,  X1 loss: 2.7776   X2 loss: 2.7985\n","====== Epoch: 148\n","====> Validation loss: 2.7472,  X1 loss: 2.7257   X2 loss: 2.7686\n","====== Epoch: 149\n","====> Validation loss: 2.7250,  X1 loss: 2.7151   X2 loss: 2.7350\n","====== Epoch: 150\n","====> Validation loss: 2.7747,  X1 loss: 2.7625   X2 loss: 2.7869\n","====== Epoch: 151\n","====> Validation loss: 2.7823,  X1 loss: 2.7724   X2 loss: 2.7922\n","====== Epoch: 152\n","====> Validation loss: 2.7384,  X1 loss: 2.7262   X2 loss: 2.7506\n","====== Epoch: 153\n","====> Validation loss: 2.7662,  X1 loss: 2.7524   X2 loss: 2.7800\n","====== Epoch: 154\n","====> Validation loss: 2.7658,  X1 loss: 2.7483   X2 loss: 2.7833\n","====== Epoch: 155\n","====> Validation loss: 2.7503,  X1 loss: 2.7404   X2 loss: 2.7603\n","====== Epoch: 156\n","====> Validation loss: 2.7698,  X1 loss: 2.7534   X2 loss: 2.7863\n","====== Epoch: 157\n","====> Validation loss: 2.7533,  X1 loss: 2.7340   X2 loss: 2.7727\n","====== Epoch: 158\n","====> Validation loss: 2.7776,  X1 loss: 2.7666   X2 loss: 2.7885\n","====== Epoch: 159\n","====> Validation loss: 2.7680,  X1 loss: 2.7612   X2 loss: 2.7748\n","====== Epoch: 160\n","====> Validation loss: 2.7646,  X1 loss: 2.7585   X2 loss: 2.7707\n","====== Epoch: 161\n","====> Validation loss: 2.7702,  X1 loss: 2.7597   X2 loss: 2.7806\n","====== Epoch: 162\n","====> Validation loss: 2.7606,  X1 loss: 2.7439   X2 loss: 2.7773\n","====== Epoch: 163\n","====> Validation loss: 2.7881,  X1 loss: 2.7670   X2 loss: 2.8092\n","====== Epoch: 164\n","====> Validation loss: 2.7774,  X1 loss: 2.7581   X2 loss: 2.7966\n","====== Epoch: 165\n","====> Validation loss: 2.7739,  X1 loss: 2.7561   X2 loss: 2.7917\n","====== Epoch: 166\n","====> Validation loss: 2.7869,  X1 loss: 2.7681   X2 loss: 2.8056\n","====== Epoch: 167\n","====> Validation loss: 2.7834,  X1 loss: 2.7676   X2 loss: 2.7993\n","====== Epoch: 168\n","====> Validation loss: 2.7860,  X1 loss: 2.7712   X2 loss: 2.8009\n","====== Epoch: 169\n","====> Validation loss: 2.7798,  X1 loss: 2.7647   X2 loss: 2.7950\n","====== Epoch: 170\n","====> Validation loss: 2.7543,  X1 loss: 2.7351   X2 loss: 2.7735\n","====== Epoch: 171\n","====> Validation loss: 2.7631,  X1 loss: 2.7468   X2 loss: 2.7794\n","====== Epoch: 172\n","====> Validation loss: 2.7497,  X1 loss: 2.7338   X2 loss: 2.7655\n","====== Epoch: 173\n","====> Validation loss: 2.7510,  X1 loss: 2.7363   X2 loss: 2.7656\n","====== Epoch: 174\n","====> Validation loss: 2.7862,  X1 loss: 2.7737   X2 loss: 2.7988\n","====== Epoch: 175\n","====> Validation loss: 2.7669,  X1 loss: 2.7566   X2 loss: 2.7772\n","====== Epoch: 176\n","====> Validation loss: 2.7924,  X1 loss: 2.7789   X2 loss: 2.8059\n","====== Epoch: 177\n","====> Validation loss: 2.7509,  X1 loss: 2.7289   X2 loss: 2.7729\n","====== Epoch: 178\n","====> Validation loss: 2.7623,  X1 loss: 2.7423   X2 loss: 2.7822\n","====== Epoch: 179\n","====> Validation loss: 2.7823,  X1 loss: 2.7692   X2 loss: 2.7953\n","====== Epoch: 180\n","====> Validation loss: 2.7750,  X1 loss: 2.7601   X2 loss: 2.7899\n","====== Epoch: 181\n","====> Validation loss: 2.7444,  X1 loss: 2.7368   X2 loss: 2.7521\n","====== Epoch: 182\n","====> Validation loss: 2.7677,  X1 loss: 2.7554   X2 loss: 2.7800\n","====== Epoch: 183\n","====> Validation loss: 2.7436,  X1 loss: 2.7239   X2 loss: 2.7633\n","====== Epoch: 184\n","====> Validation loss: 2.7898,  X1 loss: 2.7790   X2 loss: 2.8005\n","====== Epoch: 185\n","====> Validation loss: 2.8025,  X1 loss: 2.7895   X2 loss: 2.8156\n","====== Epoch: 186\n","====> Validation loss: 2.7776,  X1 loss: 2.7609   X2 loss: 2.7943\n","====== Epoch: 187\n","====> Validation loss: 2.7752,  X1 loss: 2.7674   X2 loss: 2.7831\n","====== Epoch: 188\n","====> Validation loss: 2.7526,  X1 loss: 2.7385   X2 loss: 2.7667\n","====== Epoch: 189\n","====> Validation loss: 2.7719,  X1 loss: 2.7562   X2 loss: 2.7876\n","====== Epoch: 190\n","====> Validation loss: 2.7904,  X1 loss: 2.7698   X2 loss: 2.8111\n","====== Epoch: 191\n","====> Validation loss: 2.7315,  X1 loss: 2.7175   X2 loss: 2.7455\n","====== Epoch: 192\n","====> Validation loss: 2.7790,  X1 loss: 2.7711   X2 loss: 2.7869\n","====== Epoch: 193\n","====> Validation loss: 2.7558,  X1 loss: 2.7442   X2 loss: 2.7675\n","====== Epoch: 194\n","====> Validation loss: 2.7336,  X1 loss: 2.7158   X2 loss: 2.7514\n","====== Epoch: 195\n","====> Validation loss: 2.7679,  X1 loss: 2.7492   X2 loss: 2.7866\n","====== Epoch: 196\n","====> Validation loss: 2.7566,  X1 loss: 2.7435   X2 loss: 2.7697\n","====== Epoch: 197\n","====> Validation loss: 2.7188,  X1 loss: 2.7040   X2 loss: 2.7337\n","====== Epoch: 198\n","====> Validation loss: 2.7643,  X1 loss: 2.7469   X2 loss: 2.7817\n","====== Epoch: 199\n","====> Validation loss: 2.7585,  X1 loss: 2.7430   X2 loss: 2.7739\n","====== Epoch: 200\n","====> Validation loss: 2.7892,  X1 loss: 2.7756   X2 loss: 2.8027\n","====== Epoch: 201\n","====> Validation loss: 2.7411,  X1 loss: 2.7287   X2 loss: 2.7534\n","====== Epoch: 202\n","====> Validation loss: 2.7785,  X1 loss: 2.7574   X2 loss: 2.7997\n","====== Epoch: 203\n","====> Validation loss: 2.7897,  X1 loss: 2.7809   X2 loss: 2.7985\n","====== Epoch: 204\n","====> Validation loss: 2.7501,  X1 loss: 2.7345   X2 loss: 2.7656\n","====== Epoch: 205\n","====> Validation loss: 2.7728,  X1 loss: 2.7543   X2 loss: 2.7913\n","====== Epoch: 206\n","====> Validation loss: 2.7363,  X1 loss: 2.7158   X2 loss: 2.7567\n","====== Epoch: 207\n","====> Validation loss: 2.7672,  X1 loss: 2.7570   X2 loss: 2.7775\n","====== Epoch: 208\n","====> Validation loss: 2.7545,  X1 loss: 2.7418   X2 loss: 2.7671\n","====== Epoch: 209\n","====> Validation loss: 2.7517,  X1 loss: 2.7359   X2 loss: 2.7675\n","====== Epoch: 210\n","====> Validation loss: 2.7588,  X1 loss: 2.7485   X2 loss: 2.7692\n","====== Epoch: 211\n","====> Validation loss: 2.7581,  X1 loss: 2.7442   X2 loss: 2.7721\n","====== Epoch: 212\n","====> Validation loss: 2.7385,  X1 loss: 2.7264   X2 loss: 2.7505\n","====== Epoch: 213\n","====> Validation loss: 2.7415,  X1 loss: 2.7271   X2 loss: 2.7559\n","====== Epoch: 214\n","====> Validation loss: 2.7640,  X1 loss: 2.7516   X2 loss: 2.7764\n","====== Epoch: 215\n","====> Validation loss: 2.7828,  X1 loss: 2.7699   X2 loss: 2.7957\n","====== Epoch: 216\n","====> Validation loss: 2.7500,  X1 loss: 2.7247   X2 loss: 2.7754\n","====== Epoch: 217\n","====> Validation loss: 2.7435,  X1 loss: 2.7337   X2 loss: 2.7533\n","====== Epoch: 218\n","====> Validation loss: 2.8070,  X1 loss: 2.7898   X2 loss: 2.8242\n","====== Epoch: 219\n","====> Validation loss: 2.7408,  X1 loss: 2.7289   X2 loss: 2.7526\n","====== Epoch: 220\n","====> Validation loss: 2.7451,  X1 loss: 2.7313   X2 loss: 2.7590\n","====== Epoch: 221\n","====> Validation loss: 2.7676,  X1 loss: 2.7446   X2 loss: 2.7906\n","====== Epoch: 222\n","====> Validation loss: 2.7661,  X1 loss: 2.7492   X2 loss: 2.7829\n","====== Epoch: 223\n","====> Validation loss: 2.7933,  X1 loss: 2.7854   X2 loss: 2.8013\n","====== Epoch: 224\n","====> Validation loss: 2.7445,  X1 loss: 2.7320   X2 loss: 2.7570\n","====== Epoch: 225\n","====> Validation loss: 2.7075,  X1 loss: 2.6927   X2 loss: 2.7223\n","====== Epoch: 226\n","====> Validation loss: 2.7577,  X1 loss: 2.7459   X2 loss: 2.7696\n","====== Epoch: 227\n","====> Validation loss: 2.7287,  X1 loss: 2.7162   X2 loss: 2.7412\n","====== Epoch: 228\n","====> Validation loss: 2.7354,  X1 loss: 2.7301   X2 loss: 2.7407\n","====== Epoch: 229\n","====> Validation loss: 2.7519,  X1 loss: 2.7310   X2 loss: 2.7727\n","====== Epoch: 230\n","====> Validation loss: 2.7009,  X1 loss: 2.6915   X2 loss: 2.7103\n","====== Epoch: 231\n","====> Validation loss: 2.7523,  X1 loss: 2.7395   X2 loss: 2.7651\n","====== Epoch: 232\n","====> Validation loss: 2.7436,  X1 loss: 2.7268   X2 loss: 2.7603\n","====== Epoch: 233\n","====> Validation loss: 2.7483,  X1 loss: 2.7267   X2 loss: 2.7699\n","====== Epoch: 234\n","====> Validation loss: 2.7189,  X1 loss: 2.7113   X2 loss: 2.7265\n","====== Epoch: 235\n","====> Validation loss: 2.7646,  X1 loss: 2.7569   X2 loss: 2.7722\n","====== Epoch: 236\n","====> Validation loss: 2.7446,  X1 loss: 2.7329   X2 loss: 2.7563\n","====== Epoch: 237\n","====> Validation loss: 2.7868,  X1 loss: 2.7588   X2 loss: 2.8149\n","====== Epoch: 238\n","====> Validation loss: 2.7530,  X1 loss: 2.7321   X2 loss: 2.7740\n","====== Epoch: 239\n","====> Validation loss: 2.7864,  X1 loss: 2.7737   X2 loss: 2.7991\n","====== Epoch: 240\n","====> Validation loss: 2.7535,  X1 loss: 2.7345   X2 loss: 2.7725\n","====== Epoch: 241\n","====> Validation loss: 2.7313,  X1 loss: 2.7073   X2 loss: 2.7554\n","====== Epoch: 242\n","====> Validation loss: 2.7622,  X1 loss: 2.7464   X2 loss: 2.7780\n","====== Epoch: 243\n","====> Validation loss: 2.7748,  X1 loss: 2.7553   X2 loss: 2.7943\n","====== Epoch: 244\n","====> Validation loss: 2.7761,  X1 loss: 2.7613   X2 loss: 2.7909\n","====== Epoch: 245\n","====> Validation loss: 2.7572,  X1 loss: 2.7409   X2 loss: 2.7736\n","====== Epoch: 246\n","====> Validation loss: 2.7280,  X1 loss: 2.7158   X2 loss: 2.7402\n","====== Epoch: 247\n","====> Validation loss: 2.7585,  X1 loss: 2.7389   X2 loss: 2.7782\n","====== Epoch: 248\n","====> Validation loss: 2.7593,  X1 loss: 2.7420   X2 loss: 2.7766\n","====== Epoch: 249\n","====> Validation loss: 2.7425,  X1 loss: 2.7327   X2 loss: 2.7522\n","====== Epoch: 250\n","====> Validation loss: 2.7483,  X1 loss: 2.7388   X2 loss: 2.7578\n","====== Epoch: 251\n","====> Validation loss: 2.7272,  X1 loss: 2.7142   X2 loss: 2.7402\n","====== Epoch: 252\n","====> Validation loss: 2.7760,  X1 loss: 2.7663   X2 loss: 2.7857\n","====== Epoch: 253\n","====> Validation loss: 2.7446,  X1 loss: 2.7325   X2 loss: 2.7566\n","====== Epoch: 254\n","====> Validation loss: 2.7631,  X1 loss: 2.7516   X2 loss: 2.7745\n","====== Epoch: 255\n","====> Validation loss: 2.7406,  X1 loss: 2.7234   X2 loss: 2.7578\n","====== Epoch: 256\n","====> Validation loss: 2.7317,  X1 loss: 2.7199   X2 loss: 2.7435\n","====== Epoch: 257\n","====> Validation loss: 2.7380,  X1 loss: 2.7168   X2 loss: 2.7592\n","====== Epoch: 258\n","====> Validation loss: 2.7703,  X1 loss: 2.7581   X2 loss: 2.7825\n","====== Epoch: 259\n","====> Validation loss: 2.7415,  X1 loss: 2.7288   X2 loss: 2.7541\n","====== Epoch: 260\n","====> Validation loss: 2.7983,  X1 loss: 2.7745   X2 loss: 2.8220\n","====== Epoch: 261\n","====> Validation loss: 2.8018,  X1 loss: 2.7774   X2 loss: 2.8261\n","====== Epoch: 262\n","====> Validation loss: 2.7381,  X1 loss: 2.7232   X2 loss: 2.7531\n","====== Epoch: 263\n","====> Validation loss: 2.7542,  X1 loss: 2.7374   X2 loss: 2.7711\n","====== Epoch: 264\n","====> Validation loss: 2.7459,  X1 loss: 2.7230   X2 loss: 2.7688\n","====== Epoch: 265\n","====> Validation loss: 2.7576,  X1 loss: 2.7463   X2 loss: 2.7688\n","====== Epoch: 266\n","====> Validation loss: 2.7711,  X1 loss: 2.7585   X2 loss: 2.7838\n","====== Epoch: 267\n","====> Validation loss: 2.7525,  X1 loss: 2.7300   X2 loss: 2.7751\n","====== Epoch: 268\n","====> Validation loss: 2.7747,  X1 loss: 2.7652   X2 loss: 2.7843\n","====== Epoch: 269\n","====> Validation loss: 2.7475,  X1 loss: 2.7339   X2 loss: 2.7611\n","====== Epoch: 270\n","====> Validation loss: 2.7398,  X1 loss: 2.7214   X2 loss: 2.7582\n","====== Epoch: 271\n","====> Validation loss: 2.7879,  X1 loss: 2.7745   X2 loss: 2.8013\n","====== Epoch: 272\n","====> Validation loss: 2.7593,  X1 loss: 2.7413   X2 loss: 2.7773\n","====== Epoch: 273\n","====> Validation loss: 2.7475,  X1 loss: 2.7330   X2 loss: 2.7620\n","====== Epoch: 274\n","====> Validation loss: 2.7316,  X1 loss: 2.7113   X2 loss: 2.7519\n","====== Epoch: 275\n","====> Validation loss: 2.7803,  X1 loss: 2.7634   X2 loss: 2.7971\n","====== Epoch: 276\n","====> Validation loss: 2.7623,  X1 loss: 2.7450   X2 loss: 2.7795\n","====== Epoch: 277\n","====> Validation loss: 2.7012,  X1 loss: 2.6940   X2 loss: 2.7084\n","====== Epoch: 278\n","====> Validation loss: 2.7272,  X1 loss: 2.7109   X2 loss: 2.7435\n","====== Epoch: 279\n","====> Validation loss: 2.7449,  X1 loss: 2.7230   X2 loss: 2.7667\n","====== Epoch: 280\n","====> Validation loss: 2.7491,  X1 loss: 2.7367   X2 loss: 2.7615\n","====== Epoch: 281\n","====> Validation loss: 2.7524,  X1 loss: 2.7370   X2 loss: 2.7677\n","====== Epoch: 282\n","====> Validation loss: 2.7431,  X1 loss: 2.7215   X2 loss: 2.7648\n","====== Epoch: 283\n","====> Validation loss: 2.7437,  X1 loss: 2.7256   X2 loss: 2.7618\n","====== Epoch: 284\n","====> Validation loss: 2.7307,  X1 loss: 2.7101   X2 loss: 2.7513\n","====== Epoch: 285\n","====> Validation loss: 2.7501,  X1 loss: 2.7385   X2 loss: 2.7617\n","====== Epoch: 286\n","====> Validation loss: 2.7098,  X1 loss: 2.6950   X2 loss: 2.7245\n","====== Epoch: 287\n","====> Validation loss: 2.7461,  X1 loss: 2.7240   X2 loss: 2.7682\n","====== Epoch: 288\n","====> Validation loss: 2.7582,  X1 loss: 2.7391   X2 loss: 2.7772\n","====== Epoch: 289\n","====> Validation loss: 2.7323,  X1 loss: 2.7202   X2 loss: 2.7444\n","====== Epoch: 290\n","====> Validation loss: 2.7440,  X1 loss: 2.7297   X2 loss: 2.7583\n","====== Epoch: 291\n","====> Validation loss: 2.7428,  X1 loss: 2.7264   X2 loss: 2.7591\n","====== Epoch: 292\n","====> Validation loss: 2.7881,  X1 loss: 2.7776   X2 loss: 2.7985\n","====== Epoch: 293\n","====> Validation loss: 2.7217,  X1 loss: 2.7053   X2 loss: 2.7381\n","====== Epoch: 294\n","====> Validation loss: 2.7519,  X1 loss: 2.7212   X2 loss: 2.7826\n","====== Epoch: 295\n","====> Validation loss: 2.7308,  X1 loss: 2.7124   X2 loss: 2.7492\n","====== Epoch: 296\n","====> Validation loss: 2.7697,  X1 loss: 2.7501   X2 loss: 2.7893\n","====== Epoch: 297\n","====> Validation loss: 2.7529,  X1 loss: 2.7338   X2 loss: 2.7720\n","====== Epoch: 298\n","====> Validation loss: 2.7348,  X1 loss: 2.7243   X2 loss: 2.7453\n","====== Epoch: 299\n","====> Validation loss: 2.7321,  X1 loss: 2.7099   X2 loss: 2.7544\n"]}],"source":["\n","lossi = []\n","udri = [] # update / data ratio \n","ud = []\n","\n","lr = 0.001\n","\n","for name, model in models_dict.items():\n","\n","    # Reset for the new model in the loop\n","    print(f\"+--------------New model: {name}----------------------+\")\n","    writer = SummaryWriter(log_dir=f\"runs/{name}_{time.strftime('%Y%m%d_%H%M%S')}\")\n","    model.to(device)\n","    optimizer = optim.NAdam(model.parameters(), lr=lr)\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.7)\n","    cnt = 0\n","    loss_batches = []\n","\n","\n","    for epoch in range(1, 300):\n","\n","        print(f\"====== Epoch: {epoch}\")\n","\n","        model.train()\n","        for ix_batch, (Xb_eeg, Xb_env) in enumerate(dataloader):\n","\n","            # send to device\n","            Xb_eeg = Xb_eeg.to(device)\n","            Xb_env = Xb_env.to(device)\n","\n","            # Zero out gradients\n","            optimizer.zero_grad()\n","\n","            # forward pass\n","            eeg_features, env_features, logit_scale = model(Xb_eeg, Xb_env) \n","\n","\n","            # normalize features\n","            eeg_features_n = eeg_features / eeg_features.norm(dim=1, keepdim=True)\n","            env_features_n = env_features / env_features.norm(dim=1, keepdim=True)\n","\n","            # logits\n","            logits_per_eeg = logit_scale * eeg_features_n @ env_features_n.t()\n","            logits_per_env = logits_per_eeg.t()\n","\n","            #loss function\n","            labels = torch.arange(batch_size).to(device)\n","            loss_eeg = F.cross_entropy(logits_per_eeg, labels)\n","            loss_env = F.cross_entropy(logits_per_env, labels)\n","            loss   = (loss_eeg + loss_env)/2\n","\n","            # backward pass\n","            loss.backward()\n","            optimizer.step()\n","\n","            loss_batches.append(loss.item())\n","            cnt += 1\n","\n","            with torch.no_grad():\n","                #ud = {f\"p{ix}\":(lr*p.grad.std() / p.data.std()).log10().item() for ix, p in enumerate(model.parameters()) if p.ndim==4 }\n","                #writer.add_scalars('UpdateOData/ud', ud, cnt)\n","                writer.add_scalar('Loss/train_batch', loss.item(), cnt)\n","\n","            # normalize weights\n","            with torch.no_grad():\n","                normalize_weights_eegnet(model.eeg_encoder)\n","            \n","            #break   \n","\n","        loss_epoch = loss_batches[-(ix_batch + 1):]  # mean loss across batches\n","        loss_epoch = sum(loss_epoch) / len(loss_epoch)\n","        writer.add_scalar('Loss/train_epoch', loss_epoch, epoch)\n","        #for pname, p in model.named_parameters():\n","        #writer.add_histogram(f'Params/{pname}', p, epoch)\n","        #writer.add_histogram(f'Grads/{pname}', p.grad, epoch)\n","\n","        loss_val, *_ = eval_model_cl(dl_val, model, device=device)\n","        writer.add_scalar('Loss/val_epoch', loss_val, epoch)\n","\n","        \n","\n","        model.train()\n","\n","        # Update learning rate based on epoch\n","        scheduler.step()\n","            \n","    #break   \n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["VhCK252zNjUG"],"machine_shape":"hm","provenance":[{"file_id":"13Poz5tFnEFXpegMbhqAinRdIfSvPnPge","timestamp":1677524195292}]},"gpuClass":"premium","kernelspec":{"display_name":"mne","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"8e19e54895c02f0e9343d0fbd6cee45458aaf6f05de9ab3004d10bba5525a5d0"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"736632aa328443f7a1e9a85d67da40da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0bb2a650ba0447d832f6a1bf47dd4b4":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_736632aa328443f7a1e9a85d67da40da","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">     <span style=\"color: #f92672; text-decoration-color: #f92672\"></span> <span style=\"color: #008000; text-decoration-color: #008000\">7.6/7.6 MB</span> <span style=\"color: #800000; text-decoration-color: #800000\">64.9 MB/s</span> eta <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span>\n</pre>\n","text/plain":"     \u001b[38;2;249;38;114m\u001b[0m\u001b[38;2;249;38;114m\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}}}}},"nbformat":4,"nbformat_minor":0}
