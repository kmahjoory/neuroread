{"cells":[{"cell_type":"markdown","metadata":{"id":"VhCK252zNjUG"},"source":["## COLAB TOOLS"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26650,"status":"ok","timestamp":1677624563836,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"v-pxnK4OaI-b","outputId":"34fd4042-b732-4fae-8355-b92fe9d43c9e"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":570,"referenced_widgets":["5c6a438cc4d54ffda5b0ec7afa91ebf3","4b8e354e977c40f8b81c7ed652ab6c95"]},"executionInfo":{"elapsed":10077,"status":"ok","timestamp":1677624573908,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"ZEopbadxbJH0","outputId":"e730ec04-3c43-470b-d164-3e05c24b998a"},"outputs":[{"name":"stdout","output_type":"stream","text":["['.git', '.DS_Store', '.gitignore', 'EEG', 'LICENSE', 'README.md', 'train_cl_eeg2speech_2.ipynb', 'train_cl_eeg2speech_rochester_subj_2.ipynb', 'train_cl_eeg2speech_rochester_v1.ipynb', 'train_eeg2speech_rochester.ipynb', 'train_cl_eeg2speech_rochester_v2.ipynb', 'train_cl_eeg2speech_rochester_v3.ipynb', 'train_cl_eeg2speech_rochester_v3_test.ipynb']\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n","Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n","To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","</pre>\n"],"text/plain":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Collecting mne\n","</pre>\n"],"text/plain":["Collecting mne\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n","</pre>\n"],"text/plain":["  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c6a438cc4d54ffda5b0ec7afa91ebf3","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","</pre>\n"],"text/plain":["\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mne) (23.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mne) (23.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from mne) (3.1.2)\n","</pre>\n"],"text/plain":["Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from mne) (3.1.2)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: numpy&gt;=1.15.4 in /usr/local/lib/python3.8/dist-packages (from mne) (1.22.4)\n","</pre>\n"],"text/plain":["Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.8/dist-packages (from mne) (1.22.4)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mne) (3.5.3)\n","</pre>\n"],"text/plain":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mne) (3.5.3)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pooch&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from mne) (1.6.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.8/dist-packages (from mne) (1.6.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from mne) (4.64.1)\n","</pre>\n"],"text/plain":["Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from mne) (4.64.1)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: scipy&gt;=1.1.0 in /usr/local/lib/python3.8/dist-packages (from mne) (1.7.3)\n","</pre>\n"],"text/plain":["Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from mne) (1.7.3)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from mne) (4.4.2)\n","</pre>\n"],"text/plain":["Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from mne) (4.4.2)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: requests&gt;=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch&gt;=1.5-&gt;mne) (2.25.1)\n","</pre>\n"],"text/plain":["Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.5->mne) (2.25.1)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: appdirs&gt;=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch&gt;=1.5-&gt;mne) (1.4.4)\n","</pre>\n"],"text/plain":["Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.5->mne) (1.4.4)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2-&gt;mne) (2.1.2)\n","</pre>\n"],"text/plain":["Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->mne) (2.1.2)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (4.38.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (4.38.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (0.11.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (0.11.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (2.8.2)\n","</pre>\n"],"text/plain":["Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (2.8.2)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (1.4.4)\n","</pre>\n"],"text/plain":["Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (1.4.4)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pyparsing&gt;=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (3.0.9)\n","</pre>\n"],"text/plain":["Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (3.0.9)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;mne) (8.4.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mne) (8.4.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;mne) (1.15.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->mne) (1.15.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (4.0.0)\n","</pre>\n"],"text/plain":["Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (4.0.0)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (1.26.14)\n","</pre>\n"],"text/plain":["Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.14)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (2022.12.7)\n","</pre>\n"],"text/plain":["Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.12.7)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.8/dist-packages (from requests&gt;=2.19.0-&gt;pooch&gt;=1.5-&gt;mne) (2.10)\n","</pre>\n"],"text/plain":["Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Installing collected packages: mne\n","</pre>\n"],"text/plain":["Installing collected packages: mne\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully installed mne-1.3.1\n","</pre>\n"],"text/plain":["Successfully installed mne-1.3.1\n"]},"metadata":{},"output_type":"display_data"}],"source":["\n","import os\n","import sys\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"Colab Notebooks/prj_neuroread_analysis/neuroread/\"\n","GOOGLE_DRIVE_PATH = os.path.join(\"/content\", \"drive\", \"MyDrive\", GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","\n","# Add to sys so we can import .py files.\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","os.chdir(GOOGLE_DRIVE_PATH)\n","\n","# Install unavailable packages\n","import pip\n","def import_or_install(package):\n","    try:\n","        __import__(package)\n","    except ImportError:\n","        pip.main(['install', package])\n","\n","import_or_install(\"mne\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1677624573909,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"M0LuZowEbY29"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1988,"status":"ok","timestamp":1677624575885,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"HTqIrJcOaQLu","outputId":"143e3ebf-c550-484b-f9ff-22ed2d835842"},"outputs":[{"name":"stdout","output_type":"stream","text":["Your runtime has 27.3 gigabytes of available RAM\n","\n","Tue Feb 28 22:49:33 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n"," print('Not connected to a GPU')\n","else:\n"," print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"aXEXbz7ENjUM"},"source":["## Main code"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":388,"status":"ok","timestamp":1677630966142,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"gGggzCoKZQeu","outputId":"ee09ba95-87d9-487d-9639-9849b8872d8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["import os, sys, glob\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","\n","import mne\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import time\n","\n","from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1677624595285,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"GYgZe_3OQniG"},"outputs":[],"source":["def eval_model_cl(dl, model, device=torch.device('cpu'), verbose=True):\n","    \"\"\" \n","    This function calculates the loss on data, setting backward gradients and batchnorm\n","    off. This function is written for contrasting learning where the model takes in two\n","    inputs.\n","\n","    Args:\n","\n","    Returns:\n","      loss_test: Mean loss of all test samples (scalar)\n","\n","    \"\"\"\n","    losses, losses_X1, losses_X2 = [], [], []\n","    model.to(device)  # inplace for model\n","    # Set the model in evaluation mode\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for idx_batch, (X1b, X2b) in enumerate(dl):\n","\n","            X1b = X1b.to(device)\n","            X2b = X2b.to(device)\n","\n","            X1b_features, X2b_features, logit_sc = model(X1b, X2b)\n","\n","            # Normalize features\n","            X1b_f_n = X1b_features / X1b_features.norm(dim=1, keepdim=True)\n","            X2b_f_n = X2b_features / X2b_features.norm(dim=1, keepdim=True)\n","\n","            logits_per_X1 = logit_sc * X1b_f_n @ X2b_f_n.t()\n","            logits_per_X2 = logits_per_X1.t()\n","\n","            # Number of labels equals to the 1st dimension of X1b\n","            labels = torch.arange(X1b.shape[0], device=device)\n","\n","            # Batch Loss \n","            loss_X1 = F.cross_entropy(logits_per_X1, labels)\n","            loss_X2 = F.cross_entropy(logits_per_X2, labels)\n","            loss_batch   = (loss_X1 + loss_X2) / 2\n","            losses.append(loss_batch.item())\n","            losses_X1.append(loss_X1.item())\n","            losses_X2.append(loss_X2.item())\n","\n","        # Epoch loss (mean of batch losses)\n","        loss  = sum(losses) / len(losses)\n","        loss_X1 = sum(losses_X1) / len(losses_X1)\n","        loss_X2 = sum(losses_X2) / len(losses_X2)\n","\n","        if verbose:\n","          print(f\"====> Validation loss: {loss:.4f},  X1 loss: {loss_X1:.4f}   X2 loss: {loss_X2:.4f}\")\n","\n","        return loss, loss_X1, loss_X2\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1677624596853,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"EaAsZ-SLZQey"},"outputs":[],"source":["def unfold_raw(raw, window_size=None, stride=None):\n","    \"\"\"\n","    This function unfolds raw MNE object into a list of raw objects\n","    Args:\n","        raw: a raw MNE object cropped by rejecting bad segments.\n","    Returns:\n","        raw_unfolded: a raw MNE object unfolded by applying a sliding window.\n","    \"\"\"\n","    if window_size is None:\n","        window_size = int(5 * raw.info['sfreq'])\n","    if stride is None:\n","        stride = window_size\n","    nchans = len(raw.ch_names)\n","    sig = torch.tensor(raw.get_data(), dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n","    sig_unf = F.unfold(sig, (nchans, window_size), stride=stride , padding=0)\n","    sig_unf = sig_unf.permute(0, 2, 1).reshape(-1, sig_unf.shape[-1], nchans, window_size)\n","    return sig_unf"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1677624601043,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"1cf9EoF3ZQey"},"outputs":[],"source":["def rm_repeated_annotations(raw):\n","    \"\"\"This functions taskes in raw MNE obejct and removes repeated annotations\"\"\"\n","    annots = raw.annotations.copy()\n","    annots_drop = []\n","    for k in annots:\n","        annots_drop.extend([k for kk in annots if (k['onset'] > kk['onset']) and (k['onset']+k['duration'] < kk['onset']+kk['duration']) ])\n","\n","    annots_updated = [i for i in annots if i not in annots_drop]\n","    onsets = [i['onset'] for i in annots_updated]\n","    durations = [i['duration'] for i in annots_updated]\n","    descriptions = [i['description'] for i in annots_updated]\n","    print('Initial num of annots: %d  Num of removed annots: %d  Num of retained annots:  %d' % (len(annots), len(annots_drop), len(annots_updated)))\n","    print(f' New annots: {annots_updated}')\n","    raw.set_annotations(mne.Annotations(onsets, durations, descriptions) ) \n","    return raw"]},{"cell_type":"markdown","metadata":{"id":"q4sGJAdFZQez"},"source":["## Read Data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1677629170255,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"KdQFfHcJZQe0","outputId":"34b478f8-4da0-4976-e573-7f60bd447a36"},"outputs":[{"name":"stdout","output_type":"stream","text":["-------------------------------------\n","window_size: 640  stride_size_test: 640\n","data_path: ../outputs/rochester_data/natural_speech\n"]}],"source":["subj_ids = [1, 2, 3, 4, 5]\n","fs = 128\n","window_size = int(5 * fs)\n","stride_size_train, stride_size_val, stride_size_test = int(2.5 * fs), int(5 * fs), int(5 * fs)\n","n_channs = 129 # 128 for eeg, 1 for env\n","batch_size = int(32)\n","print('-------------------------------------')\n","print(f'window_size: {window_size}  stride_size_test: {stride_size_test}')\n","\n","dataset_name = ['rochester_data', 'natural_speech']\n","outputs_path = f'../outputs/'\n","data_path = os.path.join(outputs_path, dataset_name[0], dataset_name[1])\n","print(f'data_path: {data_path}')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45634,"status":"ok","timestamp":1677624681279,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"fIhJi5IxZQe1","outputId":"05a7c008-ea38-4241-8271-1b27210dd073"},"outputs":[{"name":"stdout","output_type":"stream","text":["Opening raw data file ../outputs/rochester_data/natural_speech/subj_3/after_ica_raw.fif...\n","    Range : 0 ... 464571 =      0.000 ...  3629.461 secs\n","Ready.\n","Reading 0 ... 464571  =      0.000 ...  3629.461 secs...\n","Initial num of annots: 47  Num of removed annots: 19  Num of retained annots:  28\n"," New annots: [OrderedDict([('onset', 0.0), ('duration', 0.0), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 43.135948), ('duration', 4.115089416503906), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 121.796593), ('duration', 5.6010894775390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 176.748077), ('duration', 1.760345458984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 275.317291), ('duration', 2.994842529296875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 357.205322), ('duration', 2.126129150390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 537.65863), ('duration', 1.89752197265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 718.599854), ('duration', 2.12615966796875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 898.988525), ('duration', 1.6231689453125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1033.410278), ('duration', 0.9830322265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1101.293579), ('duration', 1.7603759765625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1266.313721), ('duration', 3.56640625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1307.502563), ('duration', 0.86865234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1438.074097), ('duration', 2.4461669921875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1583.876953), ('duration', 0.3658447265625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1613.867554), ('duration', 1.9432373046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1806.839478), ('duration', 1.9661865234375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 1982.358643), ('duration', 2.1947021484375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2162.061523), ('duration', 2.14892578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2345.888916), ('duration', 0.8916015625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2523.831299), ('duration', 2.92626953125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2707.159668), ('duration', 2.01171875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2790.049561), ('duration', 9.510498046875), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 2893.086426), ('duration', 2.400390625), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3081.215576), ('duration', 1.874755859375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3261.645996), ('duration', 2.14892578125), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3439.272217), ('duration', 2.42333984375), ('description', 'bad'), ('orig_time', None)]), OrderedDict([('onset', 3525.888916), ('duration', 1.87451171875), ('description', 'bad'), ('orig_time', None)])]\n","-------------------------------------\n","N train: 25  N val: 1  N test: 1\n","Shape Trian: torch.Size([1197, 1, 129, 640])  Shape Val: torch.Size([38, 1, 129, 640])  Shape Test: torch.Size([37, 1, 129, 640])\n","-------------------------------------\n","Shape EEG Train: torch.Size([1197, 1, 128, 640])  Val: torch.Size([38, 1, 128, 640])  Test: torch.Size([37, 1, 128, 640])\n","Mean: 2.5713672857641257e-10  Std: 6.1121818362153135e-06\n","Shape Env Train: torch.Size([1197, 1, 1, 640])  Val: torch.Size([38, 1, 1, 640])  Test: torch.Size([37, 1, 1, 640])\n","Mean Env: 2.360494613647461  Std Env: 2.5994906425476074\n"]}],"source":["raws_train_windowed, raws_val_windowed, raws_test_windowed = [], [], []\n","\n","for subj_id in subj_ids:\n","    subj_path = os.path.join(data_path, f'subj_{subj_id}')\n","\n","    # load subject raw MNE object\n","    raw = mne.io.read_raw(os.path.join(subj_path, 'after_ica_raw.fif'), preload=True)\n","    # drop M1 and M2 channels\n","    raw.drop_channels(['M1', 'M2'])\n","    assert raw.info['nchan'] == n_channs\n","\n","    raw = rm_repeated_annotations(raw)\n","    annots = raw.annotations.copy()\n","    raw_split = [raw.copy().crop(t1, t2) for t1, t2 in zip(annots.onset[:-1]+annots.duration[:-1], annots.onset[1:])]\n","\n","    # Pick the split with the longest duration for validation, supposedly less noisy\n","    ix_val = np.argmax([i.get_data().shape[1] for i in raw_split])\n","    raw_val = [raw_split.pop(ix_val)] # create a list to make it iterable. later may be used for multiple splits\n","\n","    # Pick the next split with the longest duration for testing, supposedly less noisy\n","    ix_test = np.argmax([i.get_data().shape[1] for i in raw_split])\n","    raw_test = [raw_split.pop(ix_test)]\n","    \n","    # creat list of unfolded tensor raw objects\n","    fs = raw.info['sfreq']\n","    raws_train_windowed.extend([unfold_raw(i, window_size=window_size, stride=stride_size_train) for i in raw_split if i.get_data().shape[1] > window_size])\n","    raws_val_windowed.extend([unfold_raw(i, window_size=window_size, stride=stride_size_val) for i in raw_val if i.get_data().shape[1] > window_size])\n","    raws_test_windowed.extend([unfold_raw(i, window_size=window_size, stride=stride_size_test) for i in raw_test if i.get_data().shape[1] > window_size])\n","    print(\"-------------------------------------\")\n","    print('N train: %d  N val: %d  N test: %d' % (len(raws_train_windowed), len(raws_val_windowed), len(raws_test_windowed)))\n","\n","# concatenate all in second dimension\n","sigs_train = torch.cat(raws_train_windowed, dim=1).permute(1, 0, 2, 3)\n","sigs_val = torch.cat(raws_val_windowed, dim=1).permute(1, 0, 2, 3)\n","sigs_test = torch.cat(raws_test_windowed, dim=1).permute(1, 0, 2, 3)\n","print(f\"Shape Trian: {sigs_train.shape}  Shape Val: {sigs_val.shape}  Shape Test: {sigs_test.shape}\")\n","\n","eegs_train = sigs_train[:, :, :-1, :]\n","eegs_val = sigs_val[:, :, :-1, :]\n","eegs_test = sigs_test[:, :, :-1, :]\n","print(\"-------------------------------------\")\n","print(f\"Shape EEG Train: {eegs_train.shape}  Val: {eegs_val.shape}  Test: {eegs_test.shape}\")\n","\n","# To avoid information leakage, we estimate the mean and std from the training set only.\n","mean_eeg_train =  eegs_train.mean()\n","std_eeg_train = eegs_train.std()\n","print(f\"Mean: {mean_eeg_train}  Std: {std_eeg_train}\")\n","\n","envs_train = sigs_train[:, :, [-1], :]\n","envs_val = sigs_val[:, :, [-1], :]\n","envs_test = sigs_test[:, :, [-1], :]\n","print(f\"Shape Env Train: {envs_train.shape}  Val: {envs_val.shape}  Test: {envs_test.shape}\")\n","\n","# Estimate mean and std of the Envelope data set\n","mean_env_train =  envs_train.mean()\n","std_env_train = envs_train.std()\n","print(f\"Mean Env: {mean_env_train}  Std Env: {std_env_train}\")\n","\n","# Normalize the data\n","eegs_train = (eegs_train - mean_eeg_train) / std_eeg_train\n","eegs_val = (eegs_val - mean_eeg_train) / std_eeg_train\n","eegs_test = (eegs_test - mean_eeg_train) / std_eeg_train\n","\n","envs_train = (envs_train - mean_env_train) / std_env_train\n","envs_val = (envs_val - mean_env_train) / std_env_train\n","envs_test = (envs_test - mean_env_train) / std_env_train\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tesRTfOdZQe2"},"source":["### Pytorch dataloader"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1677624687600,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"HviGOmH1ZQe2"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, eeg, env):\n","        self.eeg = eeg\n","        self.env = env\n","    \n","    def __getitem__(self, index):\n","        return self.eeg[index], self.env[index]\n","    \n","    def __len__(self):\n","        return len(self.eeg)\n","    \n","dataset_train = MyDataset(eegs_train, envs_train)\n","dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","dl_val = DataLoader(MyDataset(eegs_val, envs_val), batch_size=batch_size, shuffle=True, drop_last=True)"]},{"cell_type":"markdown","metadata":{"id":"XMjI2NeFZQe3"},"source":["## Model"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1677624687601,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"57o2oV6VZQe3"},"outputs":[],"source":["class Conv2d(nn.Conv2d):\n","    def __init__(self, in_channels, out_channels, kernel_size, **kargs):\n","        super().__init__(in_channels, out_channels, kernel_size, **kargs)\n","\n","    def __call__(self, inp):\n","        self.out = super().__call__(inp)\n","\n","        if self.out.requires_grad:\n","            self.out.retain_grad()\n","\n","        return self.out\n","    \n","    # -----------------------------------------------------------------------------------------------\n","class Flatten:\n","    \n","  def __call__(self, x):\n","    self.out = x.view(x.shape[0], -1)\n","    return self.out\n","  \n","  def parameters(self):\n","    return []\n","  \n","  # -----------------------------------------------------------------------------------------------\n","class Linear(nn.Linear):\n","    def __init__(self, x, y, **kargs):\n","        super().__init__(x, y, **kargs)\n","\n","    def __call__(self, inp):\n","        self.out = super().__call__(inp)\n","        return self.out\n","  # -----------------------------------------------------------------------------------------------\n","   \n","class ELU(nn.ELU):\n","    def __init__(self, alpha=1.0, inplace=False):\n","        super().__init__(alpha=1.0, inplace=False)\n","\n","    def __call__(self, inp):\n","        self.out = super().__call__(inp)\n","        if self.out.requires_grad:\n","            self.out.retain_grad()\n","        return self.out\n","\n","  # -----------------------------------------------------------------------------------------------\n","class Sequential:\n","  \n","    def __init__(self, layers):\n","        self.layers = layers\n","\n","    def __call__(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        self.out = x\n","        return self.out\n","\n","    def parameters(self):\n","        # get parameters of all layers and stretch them out into one list\n","        return [p for layer in self.layers for p in layer.parameters()]\n","\n","    def named_parameters(self):\n","        # get parameters of all layers and stretch them out into one list\n","        return ((n, p) for layer in self.layers for n, p in layer.named_parameters())"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1677624687601,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"IffWKmD6ZQe3"},"outputs":[],"source":["# My implementation of the shallow convnet\n","\n","fs = 64 # sampling rate\n","T = 5 * fs # number of time points in each trial\n","C = 64 # number of EEG channels\n","F1 = 8 # number of channels (depth) in the first conv layer\n","D = 2 # number of spatial filters in the second conv layer\n","F2 = D * F1 # number of channels (depth) in the pont-wise conv layer\n","num_classes = 4 # number of classes\n","\n","shallow_covnet = Sequential([\n","    Conv2d(1, 40, (1, int(fs//2)), padding='same', bias=True),\n","    Conv2d(40, 40, (C, 1), padding=(0, 0), bias=False), nn.BatchNorm2d(40, affine=True), \n","    nn.AvgPool2d((1, 75), (1, 15)), nn.Dropout(0.5),\n","    Conv2d(40, 4, kernel_size=(1, 30), padding='same', stride=(1, 1), bias=True),\n","    nn.Flatten(1, -1), # Flatten start_dim=1, end_dim=-1\n","    Linear(62*4, 4, bias=True),\n","])\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 32])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 8, 128, 640]             520\n","       BatchNorm2d-2          [-1, 8, 128, 640]              16\n","            Conv2d-3           [-1, 16, 1, 640]           2,048\n","       BatchNorm2d-4           [-1, 16, 1, 640]              32\n","               ELU-5           [-1, 16, 1, 640]               0\n","         AvgPool2d-6           [-1, 16, 1, 160]               0\n","           Dropout-7           [-1, 16, 1, 160]               0\n","            Conv2d-8           [-1, 16, 1, 160]             256\n","            Conv2d-9           [-1, 16, 1, 160]             256\n","      BatchNorm2d-10           [-1, 16, 1, 160]              32\n","              ELU-11           [-1, 16, 1, 160]               0\n","        AvgPool2d-12            [-1, 16, 1, 20]               0\n","          Dropout-13            [-1, 16, 1, 20]               0\n","          Flatten-14                  [-1, 320]               0\n","           Linear-15                   [-1, 32]          10,272\n","================================================================\n","Total params: 13,432\n","Trainable params: 13,432\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.31\n","Forward/backward pass size (MB): 10.36\n","Params size (MB): 0.05\n","Estimated Total Size (MB): 10.72\n","----------------------------------------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["/Users/keyvan.mahjoory/opt/anaconda3/envs/mne/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525699189/work/aten/src/ATen/native/Convolution.cpp:896.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]}],"source":["## EEG Encoder with LINEAR\n","\n","class EEGEncoderWithLinear(nn.Module):\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            C = 128, # number of EEG channels\n","            F1 = 8, # 8 or 4 number of channels (depth) in the first conv layer\n","            D = 2, # number of spatial filters in the second conv layer\n","            F2 = None # number of channels (depth) in the pont-wise conv layer\n","        ):\n","        super(EEGEncoderWithLinear, self).__init__()\n","\n","        if F2 is None:\n","            F2 = D * F1\n","\n","        self.eeg_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs/2)), padding='same', bias=True, groups=1),\n","            nn.BatchNorm2d(F1, affine=True),\n","            Conv2d(F1, out_channels=D*F1, kernel_size=(C, 1), padding=(0, 0), bias=False, groups=F1),\n","            nn.BatchNorm2d(D*F1, affine=True), ELU(), nn.AvgPool2d(1, 4), nn.Dropout(0.25),\n","                    \n","            Conv2d(F2, F2, (1, int(fs/(2*4))), padding='same', bias=False, groups=D*F1),\n","            Conv2d(D*F1, F2, kernel_size=(1, 1), padding=(0, 0), groups=1, bias=False),\n","            nn.BatchNorm2d(F2, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.25),\n","\n","            nn.Flatten(),\n","            nn.Linear(F2*int((T*fs)//(8*4)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.eeg_encoder(x)\n","        return x\n","\n","\n","def normalize_weights_eegnet(eeg_encoder):\n","\n","    for ix, (name, param) in enumerate(eeg_encoder.named_parameters()):\n","        if  name == 'weight' and param.ndim==4 and ix==1: # normalize conv weights to max norm 1\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=1)\n","        elif name == 'weight' and param.ndim==2: # normalize fc weights to max norm 0.25\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=0.25)\n","\n","\n","eeg_encoder_with_linear = EEGEncoderWithLinear()\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(eeg_encoder_with_linear(eegs_train[:32, :, :, :]).shape)\n","\n","summary(eeg_encoder_with_linear, (1, 128, 640))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":486,"status":"ok","timestamp":1677624688078,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"sQjEWHA4ZQe4","outputId":"a831ec80-0502-4c65-cf31-437f0ab8a6fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 320])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 8, 128, 640]             520\n","       BatchNorm2d-2          [-1, 8, 128, 640]              16\n","            Conv2d-3           [-1, 16, 1, 640]           2,048\n","       BatchNorm2d-4           [-1, 16, 1, 640]              32\n","               ELU-5           [-1, 16, 1, 640]               0\n","         AvgPool2d-6           [-1, 16, 1, 160]               0\n","           Dropout-7           [-1, 16, 1, 160]               0\n","            Conv2d-8           [-1, 16, 1, 160]             256\n","            Conv2d-9           [-1, 16, 1, 160]             256\n","      BatchNorm2d-10           [-1, 16, 1, 160]              32\n","              ELU-11           [-1, 16, 1, 160]               0\n","        AvgPool2d-12            [-1, 16, 1, 20]               0\n","          Dropout-13            [-1, 16, 1, 20]               0\n","          Flatten-14                  [-1, 320]               0\n","================================================================\n","Total params: 3,160\n","Trainable params: 3,160\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.31\n","Forward/backward pass size (MB): 10.36\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 10.68\n","----------------------------------------------------------------\n"]}],"source":["## EEG Encoder NO LINEAR\n","\n","class EEGEncoderNoLinear(nn.Module):\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            C = 128, # number of EEG channels\n","            F1 = 8, # 8 or 4 number of channels (depth) in the first conv layer\n","            D = 2, # number of spatial filters in the second conv layer\n","            F2 = None # number of channels (depth) in the pont-wise conv layer\n","        ):\n","        super(EEGEncoderNoLinear, self).__init__()\n","\n","        if F2 is None:\n","            F2 = D * F1\n","\n","        self.eeg_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs/2)), padding='same', bias=True, groups=1),\n","            nn.BatchNorm2d(F1, affine=True),\n","            Conv2d(F1, out_channels=D*F1, kernel_size=(C, 1), padding=(0, 0), bias=False, groups=F1),\n","            nn.BatchNorm2d(D*F1, affine=True), ELU(), nn.AvgPool2d(1, 4), nn.Dropout(0.25),\n","                    \n","            Conv2d(F2, F2, (1, int(fs/(2*4))), padding='same', bias=False, groups=D*F1),\n","            Conv2d(D*F1, F2, kernel_size=(1, 1), padding=(0, 0), groups=1, bias=False),\n","            nn.BatchNorm2d(F2, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.25),\n","\n","            nn.Flatten(),\n","            #nn.Linear(F2*int((T*fs)//(8*4)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.eeg_encoder(x)\n","        return x\n","\n","\n","def normalize_weights_eegnet(eeg_encoder):\n","\n","    for ix, (name, param) in enumerate(eeg_encoder.named_parameters()):\n","        if  name == 'weight' and param.ndim==4 and ix==1: # normalize conv weights to max norm 1\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=1)\n","        elif name == 'weight' and param.ndim==2: # normalize fc weights to max norm 0.25\n","            param.data = torch.renorm(param.data, 2, 0, maxnorm=0.25)\n","\n","\n","eeg_encoder_no_linear = EEGEncoderNoLinear()\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(eeg_encoder_no_linear(eegs_train[:32, :, :, :]).shape)\n","\n","summary(eeg_encoder_no_linear, (1, 128, 640))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677624688079,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"SfO-UwlzZQe4","outputId":"33e1f129-b06e-41b5-8fab-18be8534d296"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 320])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 4, 1, 640]             260\n","       BatchNorm2d-2            [-1, 4, 1, 640]               8\n","               ELU-3            [-1, 4, 1, 640]               0\n","         AvgPool2d-4            [-1, 4, 1, 320]               0\n","           Dropout-5            [-1, 4, 1, 320]               0\n","            Conv2d-6            [-1, 4, 1, 320]             512\n","       BatchNorm2d-7            [-1, 4, 1, 320]               8\n","               ELU-8            [-1, 4, 1, 320]               0\n","         AvgPool2d-9            [-1, 4, 1, 160]               0\n","          Dropout-10            [-1, 4, 1, 160]               0\n","           Conv2d-11           [-1, 16, 1, 160]           1,024\n","      BatchNorm2d-12           [-1, 16, 1, 160]              32\n","              ELU-13           [-1, 16, 1, 160]               0\n","        AvgPool2d-14            [-1, 16, 1, 20]               0\n","          Dropout-15            [-1, 16, 1, 20]               0\n","          Flatten-16                  [-1, 320]               0\n","================================================================\n","Total params: 1,844\n","Trainable params: 1,844\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.18\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.19\n","----------------------------------------------------------------\n"]}],"source":["class EnvEncoder3ConvNoLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder3ConvNoLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//8)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            #nn.Linear(F1*int((T*fs)//(2*8)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder3conv_no_linear = EnvEncoder3ConvNoLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder3conv_no_linear(envs_train[:32, :, :, :]).shape)\n","summary(env_encoder3conv_no_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 320])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 4, 1, 640]             260\n","       BatchNorm2d-2            [-1, 4, 1, 640]               8\n","               ELU-3            [-1, 4, 1, 640]               0\n","         AvgPool2d-4            [-1, 4, 1, 320]               0\n","           Dropout-5            [-1, 4, 1, 320]               0\n","            Conv2d-6           [-1, 16, 1, 320]           2,048\n","       BatchNorm2d-7           [-1, 16, 1, 320]              32\n","               ELU-8           [-1, 16, 1, 320]               0\n","         AvgPool2d-9            [-1, 16, 1, 20]               0\n","          Dropout-10            [-1, 16, 1, 20]               0\n","          Flatten-11                  [-1, 320]               0\n","================================================================\n","Total params: 2,348\n","Trainable params: 2,348\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.20\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.21\n","----------------------------------------------------------------\n"]}],"source":["class EnvEncoder2ConvNoLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder2ConvNoLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 16), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            #nn.Linear(F1*int((T*fs)//(2*8)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder2conv_no_linear = EnvEncoder2ConvNoLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder2conv_no_linear(envs_train[:32, :, :, :]).shape)\n","summary(env_encoder2conv_no_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 32])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 4, 1, 640]             260\n","       BatchNorm2d-2            [-1, 4, 1, 640]               8\n","               ELU-3            [-1, 4, 1, 640]               0\n","         AvgPool2d-4            [-1, 4, 1, 320]               0\n","           Dropout-5            [-1, 4, 1, 320]               0\n","            Conv2d-6           [-1, 16, 1, 320]           2,048\n","       BatchNorm2d-7           [-1, 16, 1, 320]              32\n","               ELU-8           [-1, 16, 1, 320]               0\n","         AvgPool2d-9            [-1, 16, 1, 20]               0\n","          Dropout-10            [-1, 16, 1, 20]               0\n","          Flatten-11                  [-1, 320]               0\n","           Linear-12                   [-1, 32]          10,272\n","================================================================\n","Total params: 12,620\n","Trainable params: 12,620\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.20\n","Params size (MB): 0.05\n","Estimated Total Size (MB): 0.25\n","----------------------------------------------------------------\n"]}],"source":["class EnvEncoder2ConvWithLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder2ConvWithLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 16), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            nn.Linear(F1*4*int((T*fs)//(8*4)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder2conv_with_linear = EnvEncoder2ConvWithLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder2conv_with_linear(envs_train[:32, :, :, :]).shape)\n","summary(env_encoder2conv_with_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 32])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 4, 1, 640]             260\n","       BatchNorm2d-2            [-1, 4, 1, 640]               8\n","               ELU-3            [-1, 4, 1, 640]               0\n","         AvgPool2d-4            [-1, 4, 1, 320]               0\n","           Dropout-5            [-1, 4, 1, 320]               0\n","            Conv2d-6            [-1, 4, 1, 320]             512\n","       BatchNorm2d-7            [-1, 4, 1, 320]               8\n","               ELU-8            [-1, 4, 1, 320]               0\n","         AvgPool2d-9            [-1, 4, 1, 160]               0\n","          Dropout-10            [-1, 4, 1, 160]               0\n","           Conv2d-11           [-1, 16, 1, 160]           1,024\n","      BatchNorm2d-12           [-1, 16, 1, 160]              32\n","              ELU-13           [-1, 16, 1, 160]               0\n","        AvgPool2d-14            [-1, 16, 1, 20]               0\n","          Dropout-15            [-1, 16, 1, 20]               0\n","          Flatten-16                  [-1, 320]               0\n","           Linear-17                   [-1, 32]          10,272\n","================================================================\n","Total params: 12,116\n","Trainable params: 12,116\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.18\n","Params size (MB): 0.05\n","Estimated Total Size (MB): 0.23\n","----------------------------------------------------------------\n"]}],"source":["class EnvEncoder3ConvWithLinear(nn.Module):\n","\n","    def __init__(self,             \n","            fs = 128, # sampling rate\n","            T = 5, # lenght of each trial in seconds\n","            F1 = 4\n","        ):\n","        super(EnvEncoder3ConvWithLinear, self).__init__()\n","\n","        self.env_encoder = nn.Sequential(\n","            Conv2d(1, F1, (1, int(fs//2)), padding='same', bias=True),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1, (1, int(fs//4)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1, affine=True), ELU(), nn.AvgPool2d(1, 2), nn.Dropout(0.5),\n","            Conv2d(F1, F1*4, (1, int(fs//8)), padding='same', bias=False, groups=1),\n","            nn.BatchNorm2d(F1*4, affine=True), ELU(), nn.AvgPool2d(1, 8), nn.Dropout(0.5),\n","            nn.Flatten(),\n","            nn.Linear(F1*4*int((T*fs)//(4*8)), int(fs/4))\n","        ) \n","\n","    def forward(self, x):\n","        x = self.env_encoder(x)\n","        return x\n","\n","env_encoder3conv_with_linear = EnvEncoder3ConvWithLinear()\n","\n","\n","# Test the model, add no grad\n","with torch.no_grad():\n","    print(env_encoder3conv_with_linear(envs_train[:32, :, :, :]).shape)\n","summary(env_encoder3conv_with_linear, (1, 1, 640))"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4789,"status":"ok","timestamp":1677624692864,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"Bp8HVS-aZQe4","outputId":"d393f94b-1dd8-42da-d79d-7fe4ba1c6d0d"},"outputs":[{"data":{"text/plain":["CES()"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["class CES(nn.Module):\n","    def __init__(self, \n","                 eeg_encoder= None,\n","                 env_encoder = None): \n","        super().__init__()\n","\n","        self.eeg_encoder = eeg_encoder\n","        self.env_encoder = env_encoder\n","        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n","\n","    def encode_eeg(self, x):\n","        return self.eeg_encoder(x)\n","    \n","    def encode_env(self, x):\n","        return self.env_encoder(x)\n","    \n","    def forward(self, eeg, env):\n","        eeg_features = self.encode_eeg(eeg)\n","        env_features = self.encode_env(env)\n","        return eeg_features, env_features, self.logit_scale.exp()\n","  \n","\n","model = CES();\n","model.to(device)\n","#for n,p in model.named_parameters():\n","    #print(n, p.shape)\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" Models with no Linear Layers\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 8, 128, 640]             520\n","       BatchNorm2d-2          [-1, 8, 128, 640]              16\n","            Conv2d-3           [-1, 16, 1, 640]           2,048\n","       BatchNorm2d-4           [-1, 16, 1, 640]              32\n","               ELU-5           [-1, 16, 1, 640]               0\n","         AvgPool2d-6           [-1, 16, 1, 160]               0\n","           Dropout-7           [-1, 16, 1, 160]               0\n","            Conv2d-8           [-1, 16, 1, 160]             256\n","            Conv2d-9           [-1, 16, 1, 160]             256\n","      BatchNorm2d-10           [-1, 16, 1, 160]              32\n","              ELU-11           [-1, 16, 1, 160]               0\n","        AvgPool2d-12            [-1, 16, 1, 20]               0\n","          Dropout-13            [-1, 16, 1, 20]               0\n","          Flatten-14                  [-1, 320]               0\n","           Conv2d-15            [-1, 4, 1, 640]             260\n","      BatchNorm2d-16            [-1, 4, 1, 640]               8\n","              ELU-17            [-1, 4, 1, 640]               0\n","        AvgPool2d-18            [-1, 4, 1, 320]               0\n","          Dropout-19            [-1, 4, 1, 320]               0\n","           Conv2d-20           [-1, 16, 1, 320]           2,048\n","      BatchNorm2d-21           [-1, 16, 1, 320]              32\n","              ELU-22           [-1, 16, 1, 320]               0\n","        AvgPool2d-23            [-1, 16, 1, 20]               0\n","          Dropout-24            [-1, 16, 1, 20]               0\n","          Flatten-25                  [-1, 320]               0\n","================================================================\n","Total params: 5,508\n","Trainable params: 5,508\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 200.00\n","Forward/backward pass size (MB): 10.56\n","Params size (MB): 0.02\n","Estimated Total Size (MB): 210.58\n","----------------------------------------------------------------\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 8, 128, 640]             520\n","       BatchNorm2d-2          [-1, 8, 128, 640]              16\n","            Conv2d-3           [-1, 16, 1, 640]           2,048\n","       BatchNorm2d-4           [-1, 16, 1, 640]              32\n","               ELU-5           [-1, 16, 1, 640]               0\n","         AvgPool2d-6           [-1, 16, 1, 160]               0\n","           Dropout-7           [-1, 16, 1, 160]               0\n","            Conv2d-8           [-1, 16, 1, 160]             256\n","            Conv2d-9           [-1, 16, 1, 160]             256\n","      BatchNorm2d-10           [-1, 16, 1, 160]              32\n","              ELU-11           [-1, 16, 1, 160]               0\n","        AvgPool2d-12            [-1, 16, 1, 20]               0\n","          Dropout-13            [-1, 16, 1, 20]               0\n","          Flatten-14                  [-1, 320]               0\n","           Conv2d-15            [-1, 4, 1, 640]             260\n","      BatchNorm2d-16            [-1, 4, 1, 640]               8\n","              ELU-17            [-1, 4, 1, 640]               0\n","        AvgPool2d-18            [-1, 4, 1, 320]               0\n","          Dropout-19            [-1, 4, 1, 320]               0\n","           Conv2d-20           [-1, 16, 1, 320]           2,048\n","      BatchNorm2d-21           [-1, 16, 1, 320]              32\n","              ELU-22           [-1, 16, 1, 320]               0\n","        AvgPool2d-23            [-1, 16, 1, 20]               0\n","          Dropout-24            [-1, 16, 1, 20]               0\n","          Flatten-25                  [-1, 320]               0\n","================================================================\n","Total params: 5,508\n","Trainable params: 5,508\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 200.00\n","Forward/backward pass size (MB): 10.56\n","Params size (MB): 0.02\n","Estimated Total Size (MB): 210.58\n","----------------------------------------------------------------\n"," Models with Linear Layers\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 8, 128, 640]             520\n","       BatchNorm2d-2          [-1, 8, 128, 640]              16\n","            Conv2d-3           [-1, 16, 1, 640]           2,048\n","       BatchNorm2d-4           [-1, 16, 1, 640]              32\n","               ELU-5           [-1, 16, 1, 640]               0\n","         AvgPool2d-6           [-1, 16, 1, 160]               0\n","           Dropout-7           [-1, 16, 1, 160]               0\n","            Conv2d-8           [-1, 16, 1, 160]             256\n","            Conv2d-9           [-1, 16, 1, 160]             256\n","      BatchNorm2d-10           [-1, 16, 1, 160]              32\n","              ELU-11           [-1, 16, 1, 160]               0\n","        AvgPool2d-12            [-1, 16, 1, 20]               0\n","          Dropout-13            [-1, 16, 1, 20]               0\n","          Flatten-14                  [-1, 320]               0\n","           Linear-15                   [-1, 32]          10,272\n","           Conv2d-16            [-1, 4, 1, 640]             260\n","      BatchNorm2d-17            [-1, 4, 1, 640]               8\n","              ELU-18            [-1, 4, 1, 640]               0\n","        AvgPool2d-19            [-1, 4, 1, 320]               0\n","          Dropout-20            [-1, 4, 1, 320]               0\n","           Conv2d-21           [-1, 16, 1, 320]           2,048\n","      BatchNorm2d-22           [-1, 16, 1, 320]              32\n","              ELU-23           [-1, 16, 1, 320]               0\n","        AvgPool2d-24            [-1, 16, 1, 20]               0\n","          Dropout-25            [-1, 16, 1, 20]               0\n","          Flatten-26                  [-1, 320]               0\n","           Linear-27                   [-1, 32]          10,272\n","================================================================\n","Total params: 26,052\n","Trainable params: 26,052\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 200.00\n","Forward/backward pass size (MB): 10.56\n","Params size (MB): 0.10\n","Estimated Total Size (MB): 210.66\n","----------------------------------------------------------------\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 8, 128, 640]             520\n","       BatchNorm2d-2          [-1, 8, 128, 640]              16\n","            Conv2d-3           [-1, 16, 1, 640]           2,048\n","       BatchNorm2d-4           [-1, 16, 1, 640]              32\n","               ELU-5           [-1, 16, 1, 640]               0\n","         AvgPool2d-6           [-1, 16, 1, 160]               0\n","           Dropout-7           [-1, 16, 1, 160]               0\n","            Conv2d-8           [-1, 16, 1, 160]             256\n","            Conv2d-9           [-1, 16, 1, 160]             256\n","      BatchNorm2d-10           [-1, 16, 1, 160]              32\n","              ELU-11           [-1, 16, 1, 160]               0\n","        AvgPool2d-12            [-1, 16, 1, 20]               0\n","          Dropout-13            [-1, 16, 1, 20]               0\n","          Flatten-14                  [-1, 320]               0\n","           Linear-15                   [-1, 32]          10,272\n","           Conv2d-16            [-1, 4, 1, 640]             260\n","      BatchNorm2d-17            [-1, 4, 1, 640]               8\n","              ELU-18            [-1, 4, 1, 640]               0\n","        AvgPool2d-19            [-1, 4, 1, 320]               0\n","          Dropout-20            [-1, 4, 1, 320]               0\n","           Conv2d-21           [-1, 16, 1, 320]           2,048\n","      BatchNorm2d-22           [-1, 16, 1, 320]              32\n","              ELU-23           [-1, 16, 1, 320]               0\n","        AvgPool2d-24            [-1, 16, 1, 20]               0\n","          Dropout-25            [-1, 16, 1, 20]               0\n","          Flatten-26                  [-1, 320]               0\n","           Linear-27                   [-1, 32]          10,272\n","================================================================\n","Total params: 26,052\n","Trainable params: 26,052\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 200.00\n","Forward/backward pass size (MB): 10.56\n","Params size (MB): 0.10\n","Estimated Total Size (MB): 210.66\n","----------------------------------------------------------------\n"]}],"source":["print(\" Models with no Linear Layers\")\n","eeg_encoder_no_linear = EEGEncoderNoLinear()\n","env_encoder3conv_no_linear = EnvEncoder2ConvNoLinear()\n","ces_eeg_0lin_env_3conv_0lin = CES(eeg_encoder=eeg_encoder_no_linear.eeg_encoder, env_encoder=env_encoder2conv_no_linear.env_encoder)\n","summary(ces_eeg_0lin_env_3conv_0lin, [(1, 128, 640), (1, 1, 640)])\n","\n","eeg_encoder_no_linear = EEGEncoderNoLinear()\n","env_encoder2conv_no_linear = EnvEncoder2ConvNoLinear()\n","ces_eeg_0lin_env_2conv_0lin = CES(eeg_encoder=eeg_encoder_no_linear.eeg_encoder, env_encoder=env_encoder2conv_no_linear.env_encoder)\n","summary(ces_eeg_0lin_env_2conv_0lin, [(1, 128, 640), (1, 1, 640)])\n","\n","\n","print(\" Models with Linear Layers\")\n","eeg_encoder_with_linear = EEGEncoderWithLinear()\n","env_encoder3conv_with_linear = EnvEncoder2ConvWithLinear()\n","ces_eeg_1lin_env_3conv_1lin = CES(eeg_encoder=eeg_encoder_with_linear.eeg_encoder, env_encoder=env_encoder3conv_with_linear.env_encoder)\n","summary(ces_eeg_1lin_env_3conv_1lin, [(1, 128, 640), (1, 1, 640)])\n","\n","eeg_encoder_with_linear = EEGEncoderWithLinear()\n","env_encoder2conv_with_linear = EnvEncoder2ConvWithLinear()\n","ces_eeg_1lin_env_2conv_1lin = CES(eeg_encoder=eeg_encoder_with_linear.eeg_encoder, env_encoder=env_encoder2conv_with_linear.env_encoder)\n","summary(ces_eeg_1lin_env_2conv_1lin, [(1, 128, 640), (1, 1, 640)])\n","\n","models_name = [\"eeg0lin_env3conv0lin\", \"eeg0lin_env2conv0lin\", \"eeg1lin_env3conv1lin\", \"eeg1lin_env2conv1lin\"]\n","models_dict = {\"eeg0lin_env3conv0lin\": ces_eeg_0lin_env_3conv_0lin, \"eeg0lin_env2conv0lin\": ces_eeg_0lin_env_2conv_0lin, \n","               \"eeg1lin_env3conv1lin\": ces_eeg_1lin_env_3conv_1lin, \"eeg1lin_env2conv1lin\": ces_eeg_1lin_env_2conv_1lin}\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281446,"status":"ok","timestamp":1677625530388,"user":{"displayName":"Keyvan Mahjoory","userId":"07918596913136132352"},"user_tz":-60},"id":"d4iJiosNZQe7","outputId":"d485f093-5f3f-4dc6-d73c-d29782441c04"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------New model: eeg0lin_env3conv0lin----------------------+\n","====== Epoch: 1\n","====> Validation loss: 3.6922,  X1 loss: 3.7004   X2 loss: 3.6840\n","====== Epoch: 2\n","====> Validation loss: 3.5937,  X1 loss: 3.5961   X2 loss: 3.5913\n","====== Epoch: 3\n","====> Validation loss: 3.6244,  X1 loss: 3.6210   X2 loss: 3.6279\n","====== Epoch: 4\n","====> Validation loss: 3.7224,  X1 loss: 3.7251   X2 loss: 3.7198\n","+--------------New model: eeg0lin_env2conv0lin----------------------+\n","====== Epoch: 1\n","====> Validation loss: 3.6075,  X1 loss: 3.6098   X2 loss: 3.6051\n","====== Epoch: 2\n","====> Validation loss: 3.6502,  X1 loss: 3.6540   X2 loss: 3.6465\n","====== Epoch: 3\n","====> Validation loss: 3.4568,  X1 loss: 3.4594   X2 loss: 3.4542\n","====== Epoch: 4\n","====> Validation loss: 3.5081,  X1 loss: 3.5073   X2 loss: 3.5089\n","+--------------New model: eeg1lin_env3conv1lin----------------------+\n","====== Epoch: 1\n","====> Validation loss: 5.3757,  X1 loss: 5.4342   X2 loss: 5.3172\n","====== Epoch: 2\n","====> Validation loss: 4.5843,  X1 loss: 4.6241   X2 loss: 4.5445\n","====== Epoch: 3\n","====> Validation loss: 4.1946,  X1 loss: 4.2173   X2 loss: 4.1720\n","====== Epoch: 4\n","====> Validation loss: 4.0780,  X1 loss: 4.0908   X2 loss: 4.0652\n","+--------------New model: eeg1lin_env2conv1lin----------------------+\n","====== Epoch: 1\n","====> Validation loss: 5.3559,  X1 loss: 5.3224   X2 loss: 5.3894\n","====== Epoch: 2\n","====> Validation loss: 4.7090,  X1 loss: 4.7863   X2 loss: 4.6316\n","====== Epoch: 3\n","====> Validation loss: 4.0752,  X1 loss: 4.0723   X2 loss: 4.0782\n","====== Epoch: 4\n","====> Validation loss: 3.7583,  X1 loss: 3.7682   X2 loss: 3.7485\n"]}],"source":["\n","lossi = []\n","udri = [] # update / data ratio \n","ud = []\n","\n","lr = 0.001\n","\n","for name, model in models_dict.items():\n","\n","    # Reset for the new model in the loop\n","    print(f\"+--------------New model: {name}----------------------+\")\n","    writer = SummaryWriter(log_dir=f\"runs/{name}_{time.strftime('%Y%m%d_%H%M%S')}\")\n","    model.to(device)\n","    optimizer = optim.NAdam(model.parameters(), lr=lr)\n","    cnt = 0\n","    loss_batches = []\n","\n","\n","    for epoch in range(1, 100):\n","\n","        print(f\"====== Epoch: {epoch}\")\n","\n","        model.train()\n","        for ix_batch, (Xb_eeg, Xb_env) in enumerate(dataloader):\n","\n","            # send to device\n","            Xb_eeg = Xb_eeg.to(device)\n","            Xb_env = Xb_env.to(device)\n","\n","            # Zero out gradients\n","            optimizer.zero_grad()\n","\n","            # forward pass\n","            eeg_features, env_features, logit_scale = model(Xb_eeg, Xb_env) \n","\n","\n","            # normalize features\n","            eeg_features_n = eeg_features / eeg_features.norm(dim=1, keepdim=True)\n","            env_features_n = env_features / env_features.norm(dim=1, keepdim=True)\n","\n","            # logits\n","            logits_per_eeg = logit_scale * eeg_features_n @ env_features_n.t()\n","            logits_per_env = logits_per_eeg.t()\n","\n","            #loss function\n","            labels = torch.arange(batch_size).to(device)\n","            loss_eeg = F.cross_entropy(logits_per_eeg, labels)\n","            loss_env = F.cross_entropy(logits_per_env, labels)\n","            loss   = (loss_eeg + loss_env)/2\n","\n","            # backward pass\n","            loss.backward()\n","            optimizer.step()\n","\n","            loss_batches.append(loss.item())\n","            cnt += 1\n","\n","            with torch.no_grad():\n","                #ud = {f\"p{ix}\":(lr*p.grad.std() / p.data.std()).log10().item() for ix, p in enumerate(model.parameters()) if p.ndim==4 }\n","                #writer.add_scalars('UpdateOData/ud', ud, cnt)\n","                writer.add_scalar('Loss/train_batch', loss.item(), cnt)\n","            \n","            #break   \n","\n","        loss_epoch = loss_batches[-(ix_batch + 1):]  # mean loss across batches\n","        loss_epoch = sum(loss_epoch) / len(loss_epoch)\n","        writer.add_scalar('Loss/train_epoch', loss_epoch, epoch)\n","        #for pname, p in model.named_parameters():\n","        #writer.add_histogram(f'Params/{pname}', p, epoch)\n","        #writer.add_histogram(f'Grads/{pname}', p.grad, epoch)\n","\n","        loss_val, *_ = eval_model_cl(dl_val, model, device=device)\n","        writer.add_scalar('Loss/val_epoch', loss_val, epoch)\n","\n","        \n","        # normalize weights\n","        with torch.no_grad():\n","            normalize_weights_eegnet(model.eeg_encoder)\n","\n","        model.train()\n","            \n","    #break   \n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"13Poz5tFnEFXpegMbhqAinRdIfSvPnPge","timestamp":1677524195292}]},"gpuClass":"standard","kernelspec":{"display_name":"mne","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"8e19e54895c02f0e9343d0fbd6cee45458aaf6f05de9ab3004d10bba5525a5d0"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"4b8e354e977c40f8b81c7ed652ab6c95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c6a438cc4d54ffda5b0ec7afa91ebf3":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_4b8e354e977c40f8b81c7ed652ab6c95","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">     <span style=\"color: #f92672; text-decoration-color: #f92672\"></span> <span style=\"color: #008000; text-decoration-color: #008000\">7.6/7.6 MB</span> <span style=\"color: #800000; text-decoration-color: #800000\">84.4 MB/s</span> eta <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span>\n</pre>\n","text/plain":"     \u001b[38;2;249;38;114m\u001b[0m\u001b[38;2;249;38;114m\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n"},"metadata":{},"output_type":"display_data"}]}}}}},"nbformat":4,"nbformat_minor":0}
